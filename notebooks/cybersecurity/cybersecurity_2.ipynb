{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#needed to preprocess the dataset\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "#general\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X1 = torch.randn(1000, 50)\n",
    "X2 = torch.randn(1000, 50) + 1.5\n",
    "X = torch.cat([X1, X2], dim=0)\n",
    "Y1 = torch.zeros(1000, 1)\n",
    "Y2 = torch.ones(1000, 1)\n",
    "Y = torch.cat([Y1, Y2], dim=0)\n",
    "print(X.size())\n",
    "print(Y.size()) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_select_categ( df):\n",
    "        dataframe = df.copy()\n",
    "        \"\"\"Applies 1 hot encoding to the proto, service and state columns but to some selected categories which are more influetial acording to seaborn countplot\"\"\"\n",
    "\n",
    "        string_columns= [\"proto\",\"service\",\"state\"]\n",
    "        string_categories= [[['tcp', 'udp', 'arp', 'ospf']],[['-', 'ftp', 'smtp', 'snmp', 'http', 'ftp-data', 'dns', 'ssh']],[['FIN', 'INT', 'CON', 'ECO', 'REQ']]]\n",
    "    \n",
    "\n",
    "        for column, categories in zip(string_columns, string_categories):       \n",
    "            column_df = dataframe.loc[:, [column]]\n",
    "\n",
    "            one_hot_encoder = OneHotEncoder(sparse=False, categories = categories,handle_unknown='ignore')\n",
    "            # Fit OneHotEncoder to dataframe\n",
    "            one_hot_encoder.fit(column_df)  \n",
    "            # Transform the dataframe\n",
    "            column_df_encoded = one_hot_encoder.transform(column_df)\n",
    "            #Create dataframe from the 2-d array\n",
    "            column_df_encoded = pd.DataFrame(data=column_df_encoded, columns=one_hot_encoder.categories_[0])\n",
    "            dataframe = pd.concat([column_df_encoded, dataframe], axis=1, sort=False)\n",
    "\n",
    "        #delete proto,service and state columns\n",
    "        dataframe = dataframe.drop(string_columns,1)\n",
    "\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_encoding_select_categ(pd.read_csv('UNSW_NB15_training-set.csv').drop(columns=['attack_cat','id']))\n",
    "df_val, df_train = df.iloc[0:35000, :], df.iloc[35000:, :]\n",
    "df_test = one_hot_encoding_select_categ(pd.read_csv('UNSW_NB15_testing-set.csv').drop(columns=['attack_cat','id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140341, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1)\n",
    "\n",
    "X_train = df_train.drop(columns='label')\n",
    "y_train = df_train.label\n",
    "\n",
    "X_val = df_val.drop(columns='label')\n",
    "y_val = df_val.label\n",
    "\n",
    "X_test = df_test.drop(columns='label')\n",
    "y_test = df_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train.values.astype('float'))\n",
    "y_train = torch.FloatTensor(y_train.values.astype('float')).reshape((-1,1))\n",
    "\n",
    "X_val = torch.FloatTensor(X_val.values.astype('float'))\n",
    "y_val = torch.FloatTensor(y_val.values.astype('float')).reshape((-1,1))\n",
    "\n",
    "X_test = torch.FloatTensor(X_test.values.astype('float'))\n",
    "y_test = torch.FloatTensor(y_test.values.astype('float')).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN architecture\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.out = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a1 = self.fc1(x)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout1 = self.dout(h1)\n",
    "        \n",
    "        a2 = self.fc2(dout1)\n",
    "        h2 = self.relu2(a2)\n",
    "        dout2 = self.dout(h2)\n",
    "        \n",
    "        a3 = self.fc3(dout2)\n",
    "        h3 = self.relu3(a3)\n",
    "        dout3 = self.dout(h3)\n",
    "        \n",
    "        a4= self.out(dout3)\n",
    "        y = self.sigmoid(a4)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, batch_size):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, X_train.size(0), batch_size):\n",
    "        x_batch = X_train[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = y_train[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # (1) Forward\n",
    "        y_hat = net(x_batch)\n",
    "        # (2) Compute diff\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        # (3) Compute gradients\n",
    "        loss.backward()\n",
    "        # (4) update weights\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test,y_test):\n",
    "    y_pred = net(X_test)\n",
    "    y_pred = y_pred.detach().numpy().flatten()\n",
    "    y_pred = y_pred == 1\n",
    "    y_true = y_test.numpy().flatten(); y_true = y_true == 1\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe with parameters to be tried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>out_loss_per_epoch</th>\n",
       "      <th>out_accuracy_val_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch  epochs     lr out_loss_per_epoch  out_accuracy_val_set\n",
       "0  10000     100  0.001                NaN                   NaN\n",
       "1  10000     100  0.005                NaN                   NaN\n",
       "2  10000     100  0.010                NaN                   NaN\n",
       "3  10000     100  0.050                NaN                   NaN\n",
       "4  10000     100  0.100                NaN                   NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat = pd.DataFrame(columns = ['batch','epochs','lr','out_loss_per_epoch', 'out_accuracy_val_set'])\n",
    "#create list with epoch,batch,lr\n",
    "listOLists = [[100,500,1_000],[10_000,5_000,1_000,500,100],[0.001,0.005,0.01,0.05,0.1,0.2]] \n",
    "for tuples in itertools.product(*listOLists):\n",
    "    row_series = pd.Series(tuples,index=['epochs','batch','lr'])\n",
    "    df_stat = df_stat.append(row_series, ignore_index = True)\n",
    "\n",
    "cols=['batch','epochs']\n",
    "df_stat[cols] = df_stat[cols].applymap(np.int32)\n",
    "df_stat['out_loss_per_epoch'] = df_stat['out_loss_per_epoch'].astype(object)\n",
    "df_stat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over the dataframe to get accuracies and losses for the several parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=39\n",
    "print('Lets try out all combinations from the dataframe..')\n",
    "for  row in tqdm(df_stat.itertuples(), total=df_stat.shape[0]):\n",
    "    #reset everything\n",
    "    net = Net(input_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    opt = optim.Adam(net.parameters(), lr=row.lr)  \n",
    "    \n",
    "    e_losses = []\n",
    "    loss_per_epoch = []\n",
    "    print('Iterating over the epochs...')\n",
    "    for epoch in tqdm(range(row.epochs)):\n",
    "        e_losses.append([train_epoch(net, opt, criterion, row.batch)])\n",
    "    \n",
    "    loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in e_losses]    \n",
    "\n",
    "    #update the dataframe with the losses and accuracy\n",
    "    df_stat.at[row.Index, 'out_loss_per_epoch'] = loss_per_epoch\n",
    "    df_stat.at[row.Index, 'out_accuracy_val_set'] = test(X_val,y_val)\n",
    "    \n",
    "    df_stat.to_csv(\"data/df_stat.csv\") #save to csv\n",
    "\n",
    "df_stats = df.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see what results we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_stats.iloc[0,3])\n",
    "df_stats.out_accuracy_val_set.max()\n",
    "df_stats.sort_values('out_accuracy_val_set', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
