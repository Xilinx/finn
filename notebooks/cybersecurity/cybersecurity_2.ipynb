{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX1 = torch.randn(1000, 50)\\nX2 = torch.randn(1000, 50) + 1.5\\nX = torch.cat([X1, X2], dim=0)\\nY1 = torch.zeros(1000, 1)\\nY2 = torch.ones(1000, 1)\\nY = torch.cat([Y1, Y2], dim=0)\\nprint(X.size())\\nprint(Y.size()) \\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#needed to preprocess the dataset\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "#general\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "X1 = torch.randn(1000, 50)\n",
    "X2 = torch.randn(1000, 50) + 1.5\n",
    "X = torch.cat([X1, X2], dim=0)\n",
    "Y1 = torch.zeros(1000, 1)\n",
    "Y2 = torch.ones(1000, 1)\n",
    "Y = torch.cat([Y1, Y2], dim=0)\n",
    "print(X.size())\n",
    "print(Y.size()) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('UNSW_NB15_training-set.csv').drop(columns=['proto','state','service','attack_cat']).set_index('id')\n",
    "df_val, df_train = df.iloc[0:35000, :], df.iloc[35000:, :]\n",
    "df_test = pd.read_csv('UNSW_NB15_testing-set.csv').drop(columns=['proto','state','service','attack_cat']).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140341, 40)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1)\n",
    "\n",
    "X_train = df_train.drop(columns='label')\n",
    "y_train = df_train.label\n",
    "\n",
    "X_val = df_val.drop(columns='label')\n",
    "y_val = df_val.label\n",
    "\n",
    "X_test = df_test.drop(columns='label')\n",
    "y_test = df_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train.values.astype('float'))\n",
    "y_train = torch.FloatTensor(y_train.values.astype('float')).reshape((-1,1))\n",
    "\n",
    "X_val = torch.FloatTensor(X_val.values.astype('float'))\n",
    "y_val = torch.FloatTensor(y_val.values.astype('float')).reshape((-1,1))\n",
    "\n",
    "X_test = torch.FloatTensor(X_test.values.astype('float'))\n",
    "y_test = torch.FloatTensor(y_test.values.astype('float')).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN architecture\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.out = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a1 = self.fc1(x)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout1 = self.dout(h1)\n",
    "        \n",
    "        a2 = self.fc2(dout1)\n",
    "        h2 = self.relu2(a2)\n",
    "        dout2 = self.dout(h2)\n",
    "        \n",
    "        a3 = self.fc3(dout2)\n",
    "        h3 = self.relu3(a3)\n",
    "        dout3 = self.dout(h3)\n",
    "        \n",
    "        a4= self.out(dout3)\n",
    "        y = self.sigmoid(a4)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, criterion, batch_size):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, X_train.size(0), batch_size):\n",
    "        x_batch = X_train[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = y_train[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # (1) Forward\n",
    "        y_hat = net(x_batch)\n",
    "        # (2) Compute diff\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        # (3) Compute gradients\n",
    "        loss.backward()\n",
    "        # (4) update weights\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test,y_test):\n",
    "    y_pred = net(X_test)\n",
    "    y_pred = y_pred.detach().numpy().flatten()\n",
    "    y_pred = y_pred == 1\n",
    "    y_true = y_test.numpy().flatten(); y_true = y_true == 1\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe with parameters to be tried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>out_loss_per_epoch</th>\n",
       "      <th>out_accuracy_val_set</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch  epochs     lr  out_loss_per_epoch  out_accuracy_val_set  index\n",
       "0  10000    1000  0.001                 NaN                   NaN      0\n",
       "1  10000    1000  0.005                 NaN                   NaN      1\n",
       "2  10000    1000  0.010                 NaN                   NaN      2\n",
       "3  10000    1000  0.050                 NaN                   NaN      3\n",
       "4  10000    1000  0.100                 NaN                   NaN      4"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat = pd.DataFrame(columns = ['batch','epochs','lr','out_loss_per_epoch', 'out_accuracy_val_set'])\n",
    "#create list with epoch,batch,lr\n",
    "listOLists = [[1_000,500,100],[10_000,5_000,1_000,500,100],[0.001,0.005,0.01,0.05,0.1,0.2]] \n",
    "for tuples in itertools.product(*listOLists):\n",
    "    row_series = pd.Series(tuples,index=['epochs','batch','lr'])\n",
    "    df_stat = df_stat.append(row_series, ignore_index = True)\n",
    "\n",
    "cols=['batch','epochs']\n",
    "df_stat[cols] = df_stat[cols].applymap(np.int32)\n",
    "df_stat['index'] = df_stat.index\n",
    "df_stat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over the dataframe to get accuracies and losses for the several parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets try out all combinations from the dataframe..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50aa0901b4f449782083cfa32b27cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=90.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over the epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbf769b1fac463184b1493b748e9b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_size=39\n",
    "print('Lets try out all combinations from the dataframe..')\n",
    "for  row in tqdm(df_stat.itertuples(), total=df_stat.shape[0]):\n",
    "    #reset everything\n",
    "    net = Net(input_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    opt = optim.Adam(net.parameters(), lr=row.lr)\n",
    "    \n",
    "    \n",
    "    e_losses = []\n",
    "    loss_per_epoch = []\n",
    "    print('Iterating over the epochs...')\n",
    "    for epoch in tqdm(range(row.epochs)):\n",
    "        e_losses.append([train_epoch(net, opt, criterion, row.batch)])\n",
    "    \n",
    "    loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in e_losses]    \n",
    "\n",
    "    #update the dataframe with the losses and accuracy\n",
    "    df_stat.at[row.index, 'out_loss_per_epoch'] = loss_per_epoch\n",
    "    df_stat.at[row.index, 'out_accuracy_val_set'] = test(X_val,y_val)\n",
    "    \n",
    "    df_stat.to_csv(\"df_stat.csv\") #save to csv\n",
    "\n",
    "df_stats = df.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see what results we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_stats.iloc[0,3])\n",
    "df_stats.out_accuracy_val_set.max()\n",
    "df_stats.sort_values('out_accuracy_val_set', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
