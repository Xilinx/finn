{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /workspace/.local/lib/python3.6/site-packages (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /workspace/.local/lib/python3.6/site-packages (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.19.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /workspace/.local/lib/python3.6/site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /workspace/.local/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (4.31.1)\n"
     ]
    }
   ],
   "source": [
    "#do not change this order \n",
    "import onnx \n",
    "import torch \n",
    "\n",
    "!pip install --user pandas\n",
    "!pip install --user scikit-learn\n",
    "!pip install --user tqdm\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from brevitas.core.quant import QuantType\n",
    "import brevitas.onnx as bo\n",
    "import onnx\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "\n",
    "from dataloader import UNSW_NB15\n",
    "from dataloader_quantized import UNSW_NB15_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brevitas import and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'brevitas_1_bit_UNSW_NB15_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f22bc83b978>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron('brevitas_1_bit_UNSW_NB15_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the model and prepare it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model in .onnx format, we can work with it using FINN. For that FINN ModelWrapper is used. It is a wrapper around the ONNX model which provides several helper functions to make it easier to work with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "model_for_sim = ModelWrapper(\"brevitas_1_bit_UNSW_NB15_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "\n",
    "model_for_sim = model_for_sim.transform(InferShapes())\n",
    "model_for_sim = model_for_sim.transform(FoldConstants())\n",
    "model_for_sim = model_for_sim.transform(GiveUniqueNodeNames())\n",
    "model_for_sim = model_for_sim.transform(GiveReadableTensorNames())\n",
    "model_for_sim = model_for_sim.transform(InferDataTypes())\n",
    "model_for_sim = model_for_sim.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the model node by node and get all outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This execution function and onnxruntime is used when `execute_onnx` from `onnx_exec` is applied to the model. The model is then simulated node by node and the result is stored in a context dictionary, which contains the values of each tensor at the end of the execution. To get the result, only the output tensor has to be extracted.\n",
    "\n",
    "The procedure is shown below. We take the model right before the nodes should be converted into HLS layers and generate an input tensor to pass to the execution function. The input tensor is generated from the Brevitas example inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.core.onnx_exec as oxe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([82332, 594])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([82332, 593])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_quantized_dataset = UNSW_NB15_quantized(file_path_train='data/UNSW_NB15_training-set.csv', \\\n",
    "                                              file_path_test = \"data/UNSW_NB15_testing-set.csv\", \\\n",
    "                                              train=False)\n",
    "input_tensor = test_quantized_dataset.data\n",
    "input_tensor = input_tensor[:,:-1]\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Shape mismatch for provided input global_in: found (1, 593) expected (2287, 593) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3d0608543875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"global_in\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp_array_k_rows\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# create the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moxe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_for_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#execute each node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moutput_pysim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#get the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/finn/src/finn/core/onnx_exec.py\u001b[0m in \u001b[0;36mexecute_onnx\u001b[0;34m(model, input_dict, return_full_exec_context, start_node, end_node)\u001b[0m\n\u001b[1;32m    173\u001b[0m                         \u001b[0minp_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_context\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                     )\n\u001b[1;32m    177\u001b[0m                 )\n",
      "\u001b[0;31mException\u001b[0m: Shape mismatch for provided input global_in: found (1, 593) expected (2287, 593) "
     ]
    }
   ],
   "source": [
    "prev_i = 0\n",
    "for i in range(2287, 82333, 2287): \n",
    "    np_array_k_rows = input_tensor[prev_i:i].detach().numpy() # select only the first k rows\n",
    "    \n",
    "    input_dict = {\"global_in\": np_array_k_rows} # create the dictionary\n",
    "    \n",
    "    output_dict = oxe.execute_onnx(model_for_sim, input_dict) #execute each node\n",
    "    output_pysim = output_dict[list(output_dict.keys())[0]] #get the output\n",
    "\n",
    "    tensor_output_pysim = torch.FloatTensor(output_pysim.astype('float')) #create output tensor\n",
    "    \n",
    "    finn_partial_array_w_sigmoid = torch.sigmoid((tensor_output_pysim)).detach().numpy() > 0.5   #pass it through sigmoid\n",
    "    finn_partial_array_w_sigmoid = finn_partial_array_w_sigmoid * 1\n",
    "    \n",
    "    finn_partial_array_before_sigmoid = tensor_output_pysim.detach().numpy()\n",
    "    \n",
    "    if prev_i == 0:\n",
    "        finn_array_w_sigmoid = finn_partial_array_w_sigmoid\n",
    "        finn_array_before_sigmoid = finn_partial_array_before_sigmoid\n",
    "    else:\n",
    "        finn_array_w_sigmoid = np.append(finn_array_w_sigmoid, finn_partial_array_w_sigmoid, axis=0)\n",
    "        finn_array_before_sigmoid = np.append(finn_array_before_sigmoid, finn_partial_array_before_sigmoid, axis=0)\n",
    "\n",
    "    prev_i = i\n",
    "    if i > 10_000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with Brevitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "brevitas_array_w_sigmoid = genfromtxt('brevitas_np_array_model_w_sigmoid.csv', delimiter=',').reshape(-1,1)\n",
    "brevitas_array_before_sigmoid = genfromtxt('brevitas_np_array_model_no_sigmoid.csv', delimiter=',').reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6238"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(finn_array_w_sigmoid,brevitas_array_w_sigmoid[:11435], atol=1e-3).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
