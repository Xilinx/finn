{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINN -  Functional Verification |  UNSW_NB15\n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "**Important: This notebook depends on the cyberbersecurity_Brevitas_1bit notebook, because we are using models that were created by this notebook. So please make sure the needed .onnx files are generated to run this notebook.**\n",
    "\n",
    "In this notebook we will show how to verify the model created by Brevitas. If this model is sucessfully verified, it can be taken all the way down to be implemented on the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /workspace/.local/lib/python3.6/site-packages (1.1.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /workspace/.local/lib/python3.6/site-packages (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.19.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /workspace/.local/lib/python3.6/site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /workspace/.local/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user pandas\n",
    "!pip install --user scikit-learn\n",
    "\n",
    "import onnx \n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------\n",
    "1. [Brevitas import and visualization](#brevitas_import_visualization)\n",
    "2. [Network preperations: Tidy up transformations](#network_preparations)\n",
    "3. [Simulate the model node by node and get all outputs](#simulate_node) \n",
    "4. [Compare with Brevitas](#compare_brevitas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Brevitas import and visualization <a id=\"brevitas_import_visualization\"></a>\n",
    "\n",
    "Now that we have the model in .onnx format, we can work with it using FINN. For that FINN ModelWrapper is used. It is a wrapper around the ONNX model which provides several helper functions to make it easier to work with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "model_file_path = \"brevitas_w1_a1NSW_NB15_model.onnx\"\n",
    "model_for_sim = ModelWrapper(model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the exported model, Netron can be used. Netron is a visualizer for neural networks and allows interactive investigation of network properties. For example, you can click on the individual nodes and view the properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'brevitas_w1_a1NSW_NB15_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f25e9bee9b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "showInNetron(model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Network preperations: Tidy up transformations <a id=\"network_preparations\"></a>\n",
    "\n",
    "This section deals with some basic transformations, which are applied to the model like a kind of \"tidy-up\" to make it easier to be processed.\n",
    "\n",
    "In the first two transformations (`GiveUniqueNodeNames`, `GiveReadableTensorNames`) the nodes in the graph are first given unique (by enumeration) names, then the tensors are given human-readable names (based on the node names). The following two transformations (`InferShapes`, `InferDataTypes`) derive the shapes and data types of the tensors from the model properties and set them in the `ValueInfo` of the model. These transformations can almost always be applied without negative effects and do not affect the structure of the graph, ensuring that all the information needed is available.\n",
    "\n",
    "The next listed transformation is `FoldConstants`, which performs constant folding. It identifies a node with constant inputs and determines its output. The result is then set as constant-only inputs for the following node and the old node is removed. Although this transformation changes the structure of the model, it is a transformation that is usually always desired and can be applied to any model. And finally, we have `RemoveStaticGraphInputs` to remove any top-level graph inputs that already have ONNX initializers associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "\n",
    "model_for_sim = model_for_sim.transform(InferShapes())\n",
    "model_for_sim = model_for_sim.transform(FoldConstants())\n",
    "model_for_sim = model_for_sim.transform(GiveUniqueNodeNames())\n",
    "model_for_sim = model_for_sim.transform(GiveReadableTensorNames())\n",
    "model_for_sim = model_for_sim.transform(InferDataTypes())\n",
    "model_for_sim = model_for_sim.transform(RemoveStaticGraphInputs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the UNSW_NB15 Test set <a id=\"Load_test_set\"></a>\n",
    "\n",
    "The UNSW_NB15_quantized class loads the csv file with the dataset, quantizes it and then returns it. Its values range between {0,1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([82332, 594])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([82332, 593])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from dataloader_quantized import UNSW_NB15_quantized\n",
    "\n",
    "test_quantized_dataset = UNSW_NB15_quantized(file_path_train='UNSW_NB15_training-set.csv', \\\n",
    "                                              file_path_test = \"UNSW_NB15_testing-set.csv\", \\\n",
    "                                              train=False)\n",
    "input_tensor = test_quantized_dataset.data[:,:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Simulate the model node by node and get all outputs <a id=\"simulate_node\"></a>\n",
    "\n",
    "The UNSW_NB15_quantized class allows to create an input tensor which will be passed to the execution function.\n",
    "\n",
    "This execution function  `execute_onnx` from `onnx_exec` library is applied to the model. The model is then simulated node by node and the result is stored in a context dictionary, which contains the values of each tensor at the end of the execution. To get the result, only the output tensor has to be extracted.\n",
    "\n",
    "The output is extracted for each one of the input, one by one, and saved inside an array which we will compare against brevitas output to see if both models (created iwth FINN and with Brevitas) are outputting the same.\n",
    "\n",
    "This next step might take several hours to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "import numpy as np\n",
    "\n",
    "prev_i = 0\n",
    "for i in range(1, input_tensor.shape[0], 1): \n",
    "    np_array_k_rows = input_tensor[prev_i:i]\n",
    "    # transform the input from {0,+1} to {-1,+1}\n",
    "    np_array_k_rows = np_array_k_rows * 2.0 - torch.tensor([1.0])\n",
    "    np_array_k_rows = np_array_k_rows.detach().numpy() # select only the first k rows\n",
    "    \n",
    "    input_dict = {\"global_in\": np_array_k_rows} # create the dictionary\n",
    "    \n",
    "    output_dict = oxe.execute_onnx(model_for_sim, input_dict) #execute each node\n",
    "    output_pysim = output_dict[list(output_dict.keys())[0]] #get the output\n",
    "    \n",
    "    finn_partial_array_after_sigmoid = torch.sigmoid(torch.from_numpy(output_pysim)).detach().numpy()\n",
    "    finn_partial_array_after_sigmoid = ((finn_partial_array_after_sigmoid > 0.5) * 1 ) *2 - 1 #shift to {-1,+1}\n",
    "    \n",
    "    if prev_i == 0:\n",
    "        finn_array_after_sigmoid  = finn_partial_array_after_sigmoid\n",
    "        \n",
    "    else:\n",
    "        finn_array_after_sigmoid = np.append(finn_array_after_sigmoid, finn_partial_array_after_sigmoid, axis=0)\n",
    "\n",
    "    prev_i = i\n",
    "    if i%10_000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare with Brevitas <a id=\"compare_brevitas\"></a>\n",
    "\n",
    "Let's see if the output of the FINN model matches the output of the Brevitas model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "brevitas_array_after_sigmoid = genfromtxt('brevitas_1_bit_model_output.csv', delimiter=',').reshape(-1,1)\n",
    "number_differences = (finn_array_after_sigmoid != brevitas_array_after_sigmoid).sum()\n",
    "if number_differences == 0:\n",
    "    print(\"Congrats! Both models are outputting the same thing. This verifies their functionality!!\")\n",
    "else:\n",
    "    print(\"Something went wrong... there are\", number_differences, \"differences out of the\", input_tensor.shape[0], \"total cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the amount of differences is zero then both models are outputting the same thing. This verifies the functionality! \n",
    "\n",
    "Now that we verified that both models output the same, we need to set the tensor datatype of the model and then save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.datatype import DataType\n",
    "global_inp_name = model_for_sim.graph.input[0].name\n",
    "model_for_sim.set_tensor_datatype(global_inp_name,  DataType.BIPOLAR)\n",
    "model_for_sim.save(model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! \n",
    "Now that you have verified the FINN model, you can take your model all the way down to implementing it on the board."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
