{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train a Quantized MLP on the UNSW_NB15 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to create, train and export a quantized Multi Layer Perceptron with binary weights and activations with Brevitas library. Specifically, we will train this quantized MLP on the quantized version of the UNSW_NB15 dataset, and then export the model to ONNX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The UNSW_NB15 Dataset Description\n",
    "The [UNSW_NB15](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/) is one of the latest dataset created by the Australian Centre for Cyber Security (ACCS). The IXIA PerfectStorm tool created more than 100GB of raw traffic. The total number of records is two million and 540,044 which are stored in four CSV files. However, only a subset is used, more specifically 257,673 records, split in two files: [\"UNSW_NB15_training-set.csv\"](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_training-set.csv) and [\" UNSW_NB15_testing-set.csv\"](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_testing-set.csv) which can be downloaded from the website.\n",
    "\n",
    "\n",
    "In this notebook a binary classification was applied, where the feature \"label\" identifies the record as an attack or as normal traffic. Prior to quantization, all features that are strings were converted to numbers with integer encoding. Quantization was done in python and mimics this [matlab script](https://github.com/TadejMurovic/BNN_Deployment/blob/master/cybersecurity_dataset_unswb15.m).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /workspace/.local/lib/python3.6/site-packages (1.1.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /workspace/.local/lib/python3.6/site-packages (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /workspace/.local/lib/python3.6/site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /workspace/.local/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.19.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (4.31.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user pandas\n",
    "!pip install --user scikit-learn\n",
    "!pip install --user tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------\n",
    "1. [Define Auxilary Method and Parameters ](#auxilary_&_parameters)\n",
    "2. [Define the quantized MLP model class](#create_model)\n",
    "3. [Define the Train and Test methods](#train_test) \n",
    "4. [Define the Loss and Optimizer](#loss_optimizer)\n",
    "5. [Load the UNSW_NB15 dataset](#load_dataset)\n",
    "6. [Train, Test and see the Loss](#train_test_loss)\n",
    "7. [Change the model structure after training](#change_model)\n",
    "8. [Brevitas export](#brevitas_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Auxilary Method and Parameters <a id='auxilary_&_parameters'></a>\n",
    "\n",
    "Before we start creating our Multi Layer Perceptron we need to define the topology structure and some needed parameters. Specifically the nodes in each layer of the MLP, the number of epochs, batch size and learning rate.\n",
    "\n",
    "Moreover, in order to watch the loss function evolution over epochs, we need to define a method for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_loss_plot(losses):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title('Loss of the model')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 593      \n",
    "hidden1 = 128      \n",
    "hidden2 = 64\n",
    "hidden3 = 32\n",
    "num_classes = 1    \n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 100 \n",
    "lr = 0.001 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the Quantized MLP model <a id='1create_model'></a>\n",
    "The model is a quantized MLP model with 1-bit weights and 1-bit activations implemented with [Brevitas](https://github.com/Xilinx/brevitas). Brevitas is a PyTorch library for quantization-aware training. The MLP has 4 FC layers, each layer has 593, 128, 64, 32 and 1 node. Between each FC layer, Batchnorm is applied. The activation function is a Quantized Identity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependencies import value\n",
    "\n",
    "from brevitas.inject import BaseInjector as Injector\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "\n",
    "class CommonQuant(Injector):\n",
    "    bit_width_impl_type = BitWidthImplType.CONST\n",
    "    scaling_impl_type = ScalingImplType.CONST\n",
    "    restrict_scaling_type = RestrictValueType.FP\n",
    "    scaling_per_output_channel = False\n",
    "    narrow_range = True\n",
    "    signed = True\n",
    "\n",
    "    @value\n",
    "    def quant_type(bit_width):\n",
    "        if bit_width is None:\n",
    "            return QuantType.FP\n",
    "        elif bit_width == 1:\n",
    "            return QuantType.BINARY\n",
    "        else:\n",
    "            return QuantType.INT\n",
    "\n",
    "class CommonWeightQuant(CommonQuant):\n",
    "    scaling_const = 1.0\n",
    "\n",
    "class CommonActQuant(CommonQuant):\n",
    "    min_val = -1.0\n",
    "    max_val = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantIdentity, QuantConv2d, QuantReLU, QuantLinear, QuantHardTanh\n",
    "import torch.nn as nn\n",
    "\n",
    "weight_bit_width = 1\n",
    "act_bit_width = 1\n",
    "\n",
    "class QuantMLP(nn.Module):\n",
    "    def __init__(self, input_size,hidden1, hidden2, hidden3, num_classes):\n",
    "        super(QuantMLP, self).__init__()\n",
    "        self.fc1   = QuantLinear(input_size, hidden1, bias=False, weight_bit_width=weight_bit_width, weight_quant=CommonWeightQuant)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden1)\n",
    "        self.identity1 = QuantIdentity(act_quant=CommonActQuant, bit_width=act_bit_width)\n",
    "        \n",
    "        self.fc2   = QuantLinear(hidden1, hidden2, bias=False, weight_bit_width=weight_bit_width, weight_quant=CommonWeightQuant)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden2)\n",
    "        self.identity2 = QuantIdentity(act_quant=CommonActQuant, bit_width=act_bit_width)\n",
    "        \n",
    "        self.fc3   = QuantLinear(hidden2, hidden3, bias=False, weight_bit_width=weight_bit_width, weight_quant=CommonWeightQuant)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(hidden3)\n",
    "        self.identity3 = QuantIdentity(act_quant=CommonActQuant, bit_width=act_bit_width)\n",
    "        \n",
    "        self.fc4   = QuantLinear(hidden3, num_classes, bias=False, weight_bit_width=weight_bit_width, weight_quant=CommonWeightQuant)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(num_classes)       \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc1 = self.fc1(x)\n",
    "        b1 = self.batchnorm1(fc1)\n",
    "        identity1 = self.identity1(b1)\n",
    "        \n",
    "        fc2 = self.fc2(identity1)\n",
    "        b2 = self.batchnorm2(fc2)\n",
    "        identity2 = self.identity2(b2)\n",
    "\n",
    "        fc3 = self.fc3(identity2)\n",
    "        b3 = self.batchnorm3(fc3)\n",
    "        identity3 = self.identity3(b3)\n",
    "        \n",
    "        fc4 = self.fc4(identity3)\n",
    "        b4 = self.batchnorm4(fc4)\n",
    "    \n",
    "        return b4\n",
    "\n",
    "model = QuantMLP(input_size, hidden1, hidden2, hidden3, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Train and Test  methods  <a id='train_test'></a>\n",
    "The train and test methods use the Dataloader, which feeds the model with a new predefined batch of training data in each iteration, until the entire training data is fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):        \n",
    "        inputs , target = data\n",
    "        optimizer.zero_grad()   \n",
    "                \n",
    "        #FORWARD PASS\n",
    "        output = model(inputs.float())\n",
    "        loss = criterion(output, target.unsqueeze(1))\n",
    "        \n",
    "        #BACKWARD AND OPTIMIZE        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # PREDICTIONS\n",
    "        pred = output.detach().numpy() > 0.5  \n",
    "        target = target.float()\n",
    "        y_true.extend(target.tolist()) \n",
    "        y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "        losses.append(loss.data.numpy()) \n",
    "        \n",
    "    model.eval()    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):    \n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            \n",
    "            inputs ,target = data\n",
    "            output = torch.sigmoid(model(inputs.float()))  \n",
    "            \n",
    "            #PREDICTIONS\n",
    "            pred = (output.detach().numpy() > 0.5) *1\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define the Loss and Optimizer <a id=\"loss_optimizer\"></a>\n",
    "\n",
    "The loss will be a BCEWithLogitsLoss. It already applies a sigmoid to its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx \n",
    "import torch\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load the UNSW_NB15 dataset <a id='load_dataset'></a>\n",
    "This UNSW_NB15_quantized class implements a PyTorch data loading utility: DataLoader, which represents a Python iterable over a dataset. This is useful because enables access to data in batches. This class contains a fully quantized dataset with values ranging {0,1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the training and test set from the [official website](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_training-set.csv\n",
    "!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_testing-set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([175341, 594])\n",
      "torch.Size([82332, 594])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from dataloader import UNSW_NB15\n",
    "from dataloader_quantized import UNSW_NB15_quantized\n",
    "\n",
    "file_path_train = \"UNSW_NB15_training-set.csv\"\n",
    "file_path_test = \"UNSW_NB15_testing-set.csv\"\n",
    "\n",
    "train_quantized_dataset = UNSW_NB15_quantized(file_path_train = file_path_train, \\\n",
    "                                              file_path_test = file_path_test, \\\n",
    "                                              train=True)\n",
    "train_quantized_loader = DataLoader(train_quantized_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_quantized_dataset = UNSW_NB15_quantized(file_path_train = file_path_train, \\\n",
    "                                              file_path_test = file_path_test, \\\n",
    "                                              train=False)\n",
    "test_quantized_loader = DataLoader(test_quantized_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train, Test the model and Verify the Loss <a id=\"train_test_loss\"></a>\n",
    "\n",
    "Now that we have everything defined, we can finally train the quantized MLP on the quantized dataset. Then, test its accuracy and watch the loss function evolution over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:51<00:00, 17.28s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "running_loss = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "        loss_epoch = train(model, train_quantized_loader, optimizer,criterion)\n",
    "        running_loss.append(loss_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8452970898314143"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model,test_quantized_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Change  the model after training <a id=\"change_model\"></a>\n",
    "\n",
    "Now that the model is trained, its output ranges {0,+1}. However, for implementation purposes we need for the output to belong to {-1,+1}. Therefore we need to add a layer before its output, such as a Quantized Identity layer. \n",
    "\n",
    "Furthermore, the input will be changed, so instead of the {0,+1} range, the model will now accept {-1,1} as valid input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the state_dict\n",
    "path = \"quantized_mlp_unsw_nb15.pt\"\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "# load the state_dict and create new model with aditional QuantIdentity layer\n",
    "new_model_to_be = QuantMLP(input_size, hidden1, hidden2, hidden3, num_classes)\n",
    "new_model_to_be.load_state_dict(torch.load(path))  \n",
    "new_model_to_be.eval()\n",
    "\n",
    "class extended_model(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(extended_model, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.identity = QuantIdentity(act_quant=CommonActQuant, bit_width=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = (x + torch.tensor([1.0])) / 2.0  # shift from {-1,1} {0,1} \n",
    "        out_original = self.pretrained(x)\n",
    "        out_final = self.identity(out_original)   # output as {-1,1}     \n",
    "        return out_final\n",
    "\n",
    "new_model = extended_model(my_pretrained_model=new_model_to_be)\n",
    "new_model.eval()\n",
    "new_model_output = new_model.forward(test_quantized_dataset.data[:,:-1] * 2.0 - torch.tensor([1.0])) # feed data as {-1,1}\n",
    "new_model_output = new_model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Brevitas export <a id=\"brevitas_export\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINN expects an ONNX model as input. This can be a model trained with [Brevitas](https://github.com/Xilinx/brevitas). First a few things have to be imported. Then the model can be loaded with the pretrained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to brevitas_w1_a1NSW_NB15_model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n"
     ]
    }
   ],
   "source": [
    "import brevitas.onnx as bo\n",
    "\n",
    "export_onnx_path = \"brevitas_w%d_a%-uNSW_NB15_model.onnx\" % (weight_bit_width, act_bit_width)\n",
    "input_shape = (1, 593)\n",
    "bo.export_finn_onnx(new_model, input_shape, export_onnx_path)\n",
    "\n",
    "new_model.eval\n",
    "print(\"Model saved to %s\" % export_onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it!\n",
    "You created, trained and tested a quantized MLP that is ready to be loaded into FINN! Congrats!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media1.tenor.com/images/2386d12e54aa11ce0298d100954d982a/tenor.gif?itemid=4115627\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
