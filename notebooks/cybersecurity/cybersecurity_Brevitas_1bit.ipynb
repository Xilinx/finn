{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /workspace/.local/lib/python3.6/site-packages (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /workspace/.local/lib/python3.6/site-packages (0.23.2)\n",
<<<<<<< HEAD
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.19.4)\n",
=======
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /workspace/.local/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.19.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /workspace/.local/lib/python3.6/site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (4.31.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user pandas\n",
    "!pip install --user scikit-learn\n",
    "!pip install --user tqdm\n",
    "\n",
    "#do not change this order\n",
    "import onnx \n",
    "import torch \n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "#\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from brevitas.nn import QuantIdentity, QuantConv2d, QuantReLU, QuantLinear, QuantHardTanh\n",
    "from brevitas.core.quant import QuantType\n",
    "\n",
    "from dataloader import UNSW_NB15\n",
    "from dataloader_quantized import UNSW_NB15_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspired by [this github file](https://github.com/alik604/cyber-security/blob/master/Intrusion-Detection/UNSW_NB15%20-%20Torch%20MLP%20and%20autoEncoder.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get UNSW_NB15 train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_training-set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_testing-set.csv"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 4,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependencies import value\n",
    "\n",
    "from brevitas.inject import BaseInjector as Injector\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "\n",
    "class CommonQuant(Injector):\n",
    "    bit_width_impl_type = BitWidthImplType.CONST\n",
    "    scaling_impl_type = ScalingImplType.CONST\n",
    "    restrict_scaling_type = RestrictValueType.FP\n",
    "    scaling_per_output_channel = False\n",
    "    narrow_range = True\n",
    "    signed = True\n",
    "\n",
    "    @value\n",
    "    def quant_type(bit_width):\n",
    "        if bit_width is None:\n",
    "            return QuantType.FP\n",
    "        elif bit_width == 1:\n",
    "            return QuantType.BINARY\n",
    "        else:\n",
    "            return QuantType.INT\n",
    "\n",
    "\n",
    "class CommonWeightQuant(CommonQuant):\n",
    "    scaling_const = 1.0\n",
    "\n",
    "\n",
    "class CommonActQuant(CommonQuant):\n",
    "    min_val = -1.0\n",
    "    max_val = 1.0"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 5,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network class\n",
    "weight_bit_width = 1\n",
    "act_bit_width = 1\n",
    "\n",
<<<<<<< HEAD
    "class QuantMLP(nn.Module):\n",
    "    def __init__(self, input_size,hidden1, hidden2, hidden3, num_classes):\n",
    "        super(QuantMLP, self).__init__()\n",
=======
    "class QuantLeNet(nn.Module):\n",
    "    def __init__(self, input_size,hidden1, hidden2, hidden3, num_classes):\n",
    "        super(QuantLeNet, self).__init__()\n",
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
    "        self.fc1   = QuantLinear(input_size, hidden1, bias=False, weight_bit_width=weight_bit_width, weight_quant=CommonWeightQuant)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden1)\n",
    "        self.identity1 = QuantIdentity(act_quant=CommonActQuant, bit_width=act_bit_width)\n",
    "        \n",
    "        self.fc2   = QuantLinear(hidden1, hidden2, bias=False, weight_bit_width=weight_bit_width, weight_quant=CommonWeightQuant)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden2)\n",
    "        self.identity2 = QuantIdentity(act_quant=CommonActQuant, bit_width=act_bit_width)\n",
    "        \n",
    "        self.fc3   = QuantLinear(hidden2, hidden3, bias=False, weight_bit_width=weight_bit_width, weight_quant=CommonWeightQuant)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(hidden3)\n",
    "        self.identity3 = QuantIdentity(act_quant=CommonActQuant, bit_width=act_bit_width)\n",
    "        \n",
    "        self.fc4   = QuantLinear(hidden3, num_classes, bias=False, weight_bit_width=weight_bit_width, weight_quant=CommonWeightQuant)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(num_classes)       \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        fc1 = self.fc1(x)\n",
    "        b1 = self.batchnorm1(fc1)\n",
    "        identity1 = self.identity1(b1)\n",
    "        \n",
    "        fc2 = self.fc2(identity1)\n",
    "        b2 = self.batchnorm2(fc2)\n",
    "        identity2 = self.identity2(b2)\n",
    "\n",
    "        fc3 = self.fc3(identity2)\n",
    "        b3 = self.batchnorm3(fc3)\n",
    "        identity3 = self.identity3(b3)\n",
    "        \n",
    "        fc4 = self.fc4(identity3)\n",
    "        b4 = self.batchnorm4(fc4)\n",
    "    \n",
    "        return b4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train,   Test   and    Display_Loss_Plot    methods"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 6,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):        \n",
    "        # get the inputs; data is a list of [inputs, target ( or labels)]\n",
    "        inputs , target = data\n",
    "        optimizer.zero_grad()   \n",
    "                \n",
    "        #FORWARD PASS\n",
    "        output = model(inputs.float())\n",
    "        loss = criterion(output, target.unsqueeze(1))\n",
    "        \n",
    "        #BACKWARD AND OPTIMIZE        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # PREDICTIONS\n",
    "        #pred = np.round(output.detach().numpy())\n",
    "        pred = output.detach().numpy() > 0.5  \n",
    "        target = target.float()\n",
    "        y_true.extend(target.tolist()) \n",
    "        y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "        losses.append(loss.data.numpy()) \n",
    "    #print(\"Accuracy on training set is\" , accuracy_score(y_true,y_pred))\n",
    "    #model.eval()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 7,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING THE MODEL\n",
    "def test(model, device, test_loader):    \n",
    "    model.eval()   #model in eval mode skips Dropout etc\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad(): # set the requires_grad flag to false as we are in the test mode\n",
    "        for data in test_loader:\n",
    "            \n",
    "            #LOAD THE DATA IN A BATCH\n",
    "            inputs ,target = data\n",
    "            \n",
    "            # the model on the data\n",
    "            output = torch.sigmoid(model(inputs.float()))  \n",
    "            \n",
    "            #PREDICTIONS\n",
    "            pred = np.round(output)\n",
    "            #pred = output.detach().numpy() > 0.5 \n",
    "            #pred = pred * 1\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 8,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_loss_plot(losses):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title('Loss of the model')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('Cross entropy loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some parameters first"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 9,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "input_size = 593      #\n",
    "hidden1 = 128      # 1st layer number of neurons\n",
    "hidden2 = 64\n",
    "hidden3 = 32\n",
    "num_classes = 1    # binary classification\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 100 \n",
    "lr = 0.001        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Neural Network class"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantMLP(input_size, hidden1, hidden2, hidden3, num_classes)"
=======
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantLeNet(input_size, hidden1, hidden2, hidden3, num_classes)\n",
    "#model.eval()"
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss and optimizer "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 70,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize UNSW_NB15 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([175341, 594])\n",
      "torch.Size([82332, 594])\n"
     ]
    }
   ],
   "source": [
    "#Get the Quantized versions \n",
    "train_quantized_dataset = UNSW_NB15_quantized(file_path_train='data/UNSW_NB15_training-set.csv', \\\n",
    "                                              file_path_test = \"data/UNSW_NB15_testing-set.csv\", \\\n",
    "                                              train=True)\n",
    "train_quantized_loader = DataLoader(train_quantized_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_quantized_dataset = UNSW_NB15_quantized(file_path_train='data/UNSW_NB15_training-set.csv', \\\n",
    "                                              file_path_test = \"data/UNSW_NB15_testing-set.csv\", \\\n",
    "                                              train=False)\n",
    "test_quantized_loader = DataLoader(test_quantized_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train, Test the model and see the loss"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 114,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 1/1 [00:20<00:00, 20.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantMLP(\n",
       "  (fc1): QuantLinear(\n",
       "    in_features=593, out_features=128, bias=False\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): BinaryQuant(\n",
       "        (scaling_impl): ConstScaling(\n",
       "          (restrict_clamp_scaling): _RestrictClampValue(\n",
       "            (restrict_value_impl): FloatRestrictValue()\n",
       "            (clamp_min_ste): Identity()\n",
       "          )\n",
       "          (value): StatelessBuffer()\n",
       "        )\n",
       "        (bit_width): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "        (delay_wrapper): DelayWrapper(\n",
       "          (delay_impl): _NoDelay()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (batchnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (identity1): QuantIdentity(\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): ClampedBinaryQuant(\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "              (clamp_min_ste): Identity()\n",
       "            )\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (bit_width): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc2): QuantLinear(\n",
       "    in_features=128, out_features=64, bias=False\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): BinaryQuant(\n",
       "        (scaling_impl): ConstScaling(\n",
       "          (restrict_clamp_scaling): _RestrictClampValue(\n",
       "            (restrict_value_impl): FloatRestrictValue()\n",
       "            (clamp_min_ste): Identity()\n",
       "          )\n",
       "          (value): StatelessBuffer()\n",
       "        )\n",
       "        (bit_width): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "        (delay_wrapper): DelayWrapper(\n",
       "          (delay_impl): _NoDelay()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (identity2): QuantIdentity(\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): ClampedBinaryQuant(\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "              (clamp_min_ste): Identity()\n",
       "            )\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (bit_width): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc3): QuantLinear(\n",
       "    in_features=64, out_features=32, bias=False\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): BinaryQuant(\n",
       "        (scaling_impl): ConstScaling(\n",
       "          (restrict_clamp_scaling): _RestrictClampValue(\n",
       "            (restrict_value_impl): FloatRestrictValue()\n",
       "            (clamp_min_ste): Identity()\n",
       "          )\n",
       "          (value): StatelessBuffer()\n",
       "        )\n",
       "        (bit_width): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "        (delay_wrapper): DelayWrapper(\n",
       "          (delay_impl): _NoDelay()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (batchnorm3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (identity3): QuantIdentity(\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (act_quant): ActQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
       "        (activation_impl): Identity()\n",
       "        (tensor_quant): ClampedBinaryQuant(\n",
       "          (scaling_impl): ConstScaling(\n",
       "            (restrict_clamp_scaling): _RestrictClampValue(\n",
       "              (restrict_value_impl): FloatRestrictValue()\n",
       "              (clamp_min_ste): Identity()\n",
       "            )\n",
       "            (value): StatelessBuffer()\n",
       "          )\n",
       "          (bit_width): BitWidthConst(\n",
       "            (bit_width): StatelessBuffer()\n",
       "          )\n",
       "          (delay_wrapper): DelayWrapper(\n",
       "            (delay_impl): _NoDelay()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc4): QuantLinear(\n",
       "    in_features=32, out_features=1, bias=False\n",
       "    (input_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (output_quant): IdentityQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "    (weight_quant): WeightQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "      (tensor_quant): BinaryQuant(\n",
       "        (scaling_impl): ConstScaling(\n",
       "          (restrict_clamp_scaling): _RestrictClampValue(\n",
       "            (restrict_value_impl): FloatRestrictValue()\n",
       "            (clamp_min_ste): Identity()\n",
       "          )\n",
       "          (value): StatelessBuffer()\n",
       "        )\n",
       "        (bit_width): BitWidthConst(\n",
       "          (bit_width): StatelessBuffer()\n",
       "        )\n",
       "        (delay_wrapper): DelayWrapper(\n",
       "          (delay_impl): _NoDelay()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bias_quant): BiasQuantProxyFromInjector(\n",
       "      (_zero_hw_sentinel): StatelessBuffer()\n",
       "    )\n",
       "  )\n",
       "  (batchnorm4): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
=======
      "100%|██████████| 3/3 [00:49<00:00, 16.66s/it]\n"
     ]
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
    }
   ],
   "source": [
    "running_loss = []\n",
    "model = QuantMLP(input_size, hidden1, hidden2, hidden3, num_classes)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "        loss_epoch = train(model, device, train_quantized_loader, optimizer,criterion)\n",
    "        running_loss.append(loss_epoch)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 115,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0.5703371714521692"
      ]
     },
     "execution_count": 14,
=======
       "0.5849123062721664"
      ]
     },
     "execution_count": 115,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(\"MLP_model\"))\n",
    "test(model,device,test_quantized_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add last layer which transforms the output to {-1,1} "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 72,
=======
   "execution_count": 117,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the state_dict\n",
<<<<<<< HEAD
    "path = \"quantized_mlp_unsw_nb15.pt\"\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "# load the state_dict and create new model with aditional QuantIdentity layer\n",
    "new_model_to_be = QuantMLP(input_size, hidden1, hidden2, hidden3, num_classes)\n",
    "new_model_to_be.load_state_dict(torch.load(path))  \n",
    "new_model_to_be.eval()\n",
    "\n",
    "class extended_model(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(extended_model, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.identity = QuantIdentity(act_quant=CommonActQuant, bit_width=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_original = self.pretrained(x)\n",
    "        out_final = self.identity(out_original)       \n",
    "        return out_final\n",
    "\n",
    "new_model = extended_model(my_pretrained_model=new_model_to_be)\n",
    "new_model_output = new_model.forward(test_quantized_dataset.data[:,:-1])\n",
    "new_model_output = new_model_output"
=======
    "model.eval()\n",
    "path = \"quantized_mlp_unsw_nb15.pt\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       ...,\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the state_dict and create new model with aditional QuantIdentity layer\n",
    "new_model_to_be = QuantLeNet(input_size, hidden1, hidden2, hidden3, num_classes)\n",
    "new_model_to_be.load_state_dict(torch.load(path))  \n",
    "new_model_to_be.eval()\n",
    "\n",
    "class extended_model(nn.Module):\n",
    "    def __init__(self, my_pretrained_model):\n",
    "        super(extended_model, self).__init__()\n",
    "        self.pretrained = my_pretrained_model\n",
    "        self.identity = QuantIdentity(act_quant=CommonActQuant,bit_width=act_bit_width)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_original = self.pretrained(x)\n",
    "        out_adjusted = out_original - 0.5\n",
    "        out_final = self.identity(out_adjusted)\n",
    "        return out_final\n",
    "\n",
    "\n",
    "new_model = extended_model(my_pretrained_model=new_model_to_be)\n",
    "new_model_output = new_model.forward(test_quantized_dataset.data[:,:-1])\n",
    "new_model_output = new_model_output.detach().numpy()\n",
    "new_model_output"
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model_output = model.forward(test_quantized_dataset.data[:,:-1])\n",
    "\n",
    "old_model_output = torch.sigmoid(old_model_output).detach().numpy()\n",
    "old_model_output = old_model_output > 0.5\n",
    "old_model_output = old_model_output *1\n",
    "old_model_output = old_model_output*2 -1"
=======
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.9156, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(new_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       ...,\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_model_output = torch.sigmoid(model.forward(test_quantized_dataset.data[:,:-1])).detach().numpy()\n",
    "old_model_output = np.round(old_model_output) \n",
    "old_model_output = old_model_output*2 -1\n",
    "old_model_output"
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 74,
=======
   "execution_count": 125,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "82332"
      ]
     },
     "execution_count": 74,
=======
       "38031"
      ]
     },
     "execution_count": 125,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "np.isclose(old_model_output, new_model_output.detach().numpy(), atol=1e-1).sum()"
=======
    "np.isclose(old_model_output, new_model_output, atol=1e-1).sum()"
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create files to verify the model after Brevitas export"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 66,
=======
   "execution_count": null,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
<<<<<<< HEAD
    "raw_output = new_model.forward(test_quantized_dataset.data[:,:-1])\n",
    "np.savetxt(\"brevitas_1_bit_model_after_sigmoid.csv\", raw_output.detach().numpy(), delimiter=\",\")"
=======
    "raw_output = model.forward(test_quantized_dataset.data[:,:-1])\n",
    "np.savetxt(\"brevitas_1_bit_model_no_sigmoid.csv\", raw_output.detach().numpy(), delimiter=\",\")\n",
    "raw_output"
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Brevitas model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 65,
=======
   "execution_count": null,
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to brevitas_w1_a1NSW_NB15_model.onnx\n"
     ]
    }
   ],
   "source": [
    "#do not change this order\n",
    "import onnx \n",
    "import torch \n",
    "import brevitas.onnx as bo\n",
    "\n",
    "export_onnx_path = \"brevitas_w%d_a%-uNSW_NB15_model.onnx\" % (weight_bit_width, act_bit_width)\n",
    "#export_onnx_path = \"brevitas1BitUnswnb15.onnx\"\n",
    "input_shape = (2287, 593)\n",
<<<<<<< HEAD
    "bo.export_finn_onnx(new_model, input_shape, export_onnx_path)\n",
=======
    "bo.export_finn_onnx(model, input_shape, export_onnx_path)\n",
>>>>>>> 3c06b0a7b3894b9eb5377a63ddbd69f42cefde8b
    "print(\"Model saved to %s\" % export_onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
