{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#needed to create the Neural Network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#general\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspired by [this github file](https://github.com/alik604/cyber-security/blob/master/Intrusion-Detection/UNSW_NB15%20-%20Torch%20MLP%20and%20autoEncoder.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get UNSW_NB15 train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_training-set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_testing-set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define UNSW_NB15 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNSW_NB15(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, sequence_length=25, transform=None):\n",
    "        #TODO have a sequence_overlap=True flag? Does overlap matter?\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        self.columns = ['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
    "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
    "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
    "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
    "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
    "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
    "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
    "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n",
    "        self.dtypes = dtypes = {\"id\":\"int32\",\n",
    "                                \"scrip\": \"string\",\n",
    "                                #\"sport\": \"int32\",\n",
    "                                \"dstip\": \"string\",\n",
    "                                #\"dsport\": \"int32\",\n",
    "                                \"proto\": \"string\",\n",
    "                                \"state\": \"string\",\n",
    "                                \"dur\": \"float64\",\n",
    "                                \"sbytes\": \"int32\",\n",
    "                                \"dbytes\": \"int32\",\n",
    "                                \"sttl\": \"int32\",\n",
    "                                \"dttl\": \"int32\",\n",
    "                                \"sloss\": \"int32\",\n",
    "                                \"dloss\": \"int32\",\n",
    "                                \"service\": \"string\",\n",
    "                                \"sload\": \"float64\",\n",
    "                                \"dload\": \"float64\",\n",
    "                                \"spkts\": \"int32\",\n",
    "                                \"dpkts\": \"int32\",\n",
    "                                \"swin\": \"int32\",\n",
    "                                \"dwin\": \"int32\",\n",
    "                                \"stcpb\": \"int32\",\n",
    "                                \"dtcpb\": \"int32\", \n",
    "                                #\"smeansz\": \"int32\",\n",
    "                                #\"dmeansz\": \"int32\",\n",
    "                                \"trans_depth\": \"int32\",\n",
    "                                #\"res_bdy_len\": \"int32\",\n",
    "                                \"sjit\": \"float64\",\n",
    "                                \"djit\": \"float64\",\n",
    "                                #\"stime\": \"int64\",\n",
    "                                #\"ltime\": \"int64\",\n",
    "                                #\"sintpkt\": \"float64\",\n",
    "                                #\"dintpkt\": \"float64\",\n",
    "                                \"tcprtt\": \"float64\",\n",
    "                                \"synack\": \"float64\",\n",
    "                                \"ackdat\": \"float64\",\n",
    "\n",
    "                                #commenting these because they have mixed values and we aren't going to generate them anyway\n",
    "                                #\"is_sm_ips_ports\": \"int32\",\n",
    "                                #\"ct_state_ttl\": \"int32\",\n",
    "                                #\"ct_flw_httpd_mthd\": \"int32\",\n",
    "                                #\"is_ftp_login\": \"int32\",\n",
    "                                #\"is_ftp_cmd\": \"int32\",\n",
    "                                #\"ct_ftp_cmd\": \"int32\",\n",
    "                                #\"ct_srv_src\": \"int32\",\n",
    "                                ##\"ct_dst_ltm\": \"int32\", \n",
    "                                #\"ct_src_ltm\": \"int32\",\n",
    "                                #\"ct_src_dport_ltm\": \"int32\",\n",
    "                                #\"ct_dst_sport_ltm\": \"int32\",\n",
    "                                #\"ct_dst_src_ltm\": \"int32\",\n",
    "                                \"attack_cat\": \"string\",\n",
    "                                \"label\": \"int32\"}\n",
    "        self.categorical_column_values = {\"proto\":None, \"state\":None, \"service\":None, \"attack_cat\":None}\n",
    "\n",
    "        self.dataframe = pd.read_csv(file_path, encoding=\"latin-1\", names=self.columns,header=0, dtype=self.dtypes)\n",
    "        #self.dataframe.sort_values(by=['stime']) #sort chronologically upon loading\n",
    "        \n",
    "        #load all the unique values of categorical features at the start\n",
    "        #and make these accessible via a fast function call.\n",
    "        for key in self.categorical_column_values:\n",
    "            self.categorical_column_values[key] = self.dataframe[key].unique()\n",
    "\n",
    "        #cache all the maximum values in numeric columns since we'll be using these for feature extraction\n",
    "        self.maximums = {}\n",
    "        for key in self.dtypes:\n",
    "            if \"int\" in self.dtypes[key] or \"float\" in self.dtypes[key]:\n",
    "                self.maximums[key] = max(self.dataframe[key])\n",
    "        \n",
    "        #------------------------------------------------\n",
    "        self.dataframe = self.dataframe.drop(['id'],1)\n",
    "               \n",
    "       \n",
    "        ##------Encoding string columns with value between 0 and n_classes-1----\n",
    "        #le = preprocessing.LabelEncoder()\n",
    "        #self.dataframe['attack_cat_encoded'] = le.fit_transform(self.dataframe['attack_cat'])\n",
    "        #self.dataframe['proto_encoded'] = le.fit_transform(self.dataframe['proto'])\n",
    "        #self.dataframe['service_encoded'] = le.fit_transform(self.dataframe['service'])\n",
    "        #self.dataframe['state_encoded'] = le.fit_transform(self.dataframe['state'])\n",
    "        #self.dataframe['state_encoded'], uniques = pd.factorize(self.dataframe.state)\n",
    "        \n",
    "        # ----------Normalising all numerical features--------------\n",
    "        #cols_to_normalise = list(self.dataframe.columns.values)[:39]\n",
    "        #self.dataframe[cols_to_normalise] = self.dataframe[cols_to_normalise].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        #self.dataframe[cols_to_normalise] = self.dataframe[cols_to_normalise].apply(lambda x: (x - x.min()) / (x.max() - x.min()))               \n",
    "        \n",
    "        #-----------Create pytorch tensor----------------\n",
    "        #self.tensor = torch.Tensor(self.dataframe.values)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_tensor(self):\n",
    "        return self.tensor\n",
    "    \n",
    "    def get_dataframe(self):\n",
    "        return self.dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe.index) - self.sequence_length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #TODO need error checking for out of bounds?\n",
    "        #TODO return x,y where y is the category of the example\n",
    "        #since none corresponds to \"normal\" data\n",
    "        \n",
    "        list_of_dicts = []\n",
    "        for i in range(index,index+self.sequence_length):\n",
    "            list_of_dicts.append(self.dataframe.loc[i, :].to_dict())\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            return self.transform(self, list_of_dicts)\n",
    "        \n",
    "        return list_of_dicts\n",
    "    \n",
    "    #get a list of all the unique labels in the dataset\n",
    "    def get_labels(self):\n",
    "        return self.dataframe['label'].unique().tolist()\n",
    "    \n",
    "    #get a list of all the unique attack categories in the dataset\n",
    "    def get_attack_categories(self):\n",
    "        return self.dataframe['attack_cat'].unique().tolist()\n",
    "    \n",
    "    def get_list_of_categories(self, column_name):\n",
    "        pass #TODO\n",
    "\n",
    "    #limit the dataset to only examples in the specified category\n",
    "    def use_only_category(self, category_name):\n",
    "        if category_name not in self.get_attack_categories():\n",
    "            return False\n",
    "        \n",
    "        new_dataframe = self.dataframe[self.dataframe['attack_cat'] == category_name]\n",
    "        new_dataframe = new_dataframe.reset_index()\n",
    "        self.dataframe = new_dataframe\n",
    "        return True\n",
    "    \n",
    "    #limit the dataset to only examples with the specified label\n",
    "    def use_only_label(self, label):\n",
    "        if label not in self.get_labels():\n",
    "            return False\n",
    "        \n",
    "        new_dataframe = self.dataframe[self.dataframe['label'] == label]\n",
    "        new_dataframe = new_dataframe.reset_index()\n",
    "        self.dataframe = new_dataframe\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size_2, num_classes):\n",
    "        super(Net,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        # linear layer (input_size -> hidden_size)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # linear layer (hidden_size -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size_2)\n",
    "        # linear layer (hidden_size_2 -> num_classes)\n",
    "        self.fc3 = nn.Linear(hidden_size_2, num_classes)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.droput = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.elu = nn.ELU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #x is the input tensor\n",
    "        out = self.fc1(x)\n",
    "        #add hidden layer, with relu activation function\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # add hidden layer, with relu activation function\n",
    "        out = self.relu(out)\n",
    "        # add dropout instead of relu or not..?\n",
    "        #out = self.droput(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize UNSW_NB15 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_nb15_training = UNSW_NB15(file_path ='UNSW_NB15_training-set.csv')\n",
    "training = unsw_nb15_training.get_dataframe()\n",
    "\n",
    "unsw_nb15_testing = UNSW_NB15(file_path ='UNSW_NB15_testing-set.csv')\n",
    "testing = unsw_nb15_testing.get_dataframe()\n",
    "\n",
    "#combine both\n",
    "training['train'] = 1\n",
    "testing['train'] = 0\n",
    "combined = pd.concat([training, testing])\n",
    "\n",
    "#do the integer encoding \n",
    "le = preprocessing.LabelEncoder()\n",
    "#combined['attack_cat_encoded'] = le.fit_transform(combined['attack_cat'])\n",
    "#combined['proto_encoded'] = le.fit_transform(combined['proto'])\n",
    "#combined['service_encoded'] = le.fit_transform(combined['service'])\n",
    "#combined['state_encoded'] = le.fit_transform(combined['state'])\n",
    "#combined['state_encoded'], uniques = pd.factorize(self.dataframe.state)\n",
    "\n",
    "combined['attack_cat'] = le.fit_transform(combined['attack_cat'])\n",
    "combined['proto'] = le.fit_transform(combined['proto'])\n",
    "combined['service'] = le.fit_transform(combined['service'])\n",
    "combined['state'] = le.fit_transform(combined['state'])\n",
    "\n",
    "\n",
    "#split trainng and testing again\n",
    "training = combined [combined['train']== 1]\n",
    "testing = combined [combined['train']== 0]\n",
    "training.drop(['train'],1)\n",
    "\n",
    "x_training = training.iloc[:, 0:-1].values\n",
    "y_training = training.iloc[:, -1].values # Last two (or 1 ?) columns are categories and labels\n",
    "x_testing = testing.iloc[:, 0:-1].values\n",
    "y_testing = testing.iloc[:, -1].values # Last two (or 1 ?) columns are categories and labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test to see if encoding is the same for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_encoded</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>attack_cat_encoded</th>\n",
       "      <th>service</th>\n",
       "      <th>service_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIN</td>\n",
       "      <td>4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>INT</td>\n",
       "      <td>5</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>snmp</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CON</td>\n",
       "      <td>2</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>ftp</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>ECO</td>\n",
       "      <td>3</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>REQ</td>\n",
       "      <td>7</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>RST</td>\n",
       "      <td>8</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18916</th>\n",
       "      <td>PAR</td>\n",
       "      <td>6</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20806</th>\n",
       "      <td>URN</td>\n",
       "      <td>9</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20808</th>\n",
       "      <td>no</td>\n",
       "      <td>10</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  state_encoded attack_cat  attack_cat_encoded service  \\\n",
       "0       FIN              4     Normal                   6       -   \n",
       "15      INT              5     Normal                   6    snmp   \n",
       "22      CON              2     Normal                   6     ftp   \n",
       "141     ECO              3     Normal                   6       -   \n",
       "746     REQ              7     Normal                   6       -   \n",
       "4749    RST              8     Normal                   6       -   \n",
       "18916   PAR              6     Normal                   6       -   \n",
       "20806   URN              9     Normal                   6       -   \n",
       "20808    no             10     Normal                   6       -   \n",
       "\n",
       "       service_encoded  \n",
       "0                    0  \n",
       "15                  10  \n",
       "22                   3  \n",
       "141                  0  \n",
       "746                  0  \n",
       "4749                 0  \n",
       "18916                0  \n",
       "20806                0  \n",
       "20808                0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_subset = training.loc[:, ['state','state_encoded','attack_cat','attack_cat_encoded','service','service_encoded']]\n",
    "training_subset[~training_subset.duplicated('state')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_encoded</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>attack_cat_encoded</th>\n",
       "      <th>service</th>\n",
       "      <th>service_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INT</td>\n",
       "      <td>5</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FIN</td>\n",
       "      <td>4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>REQ</td>\n",
       "      <td>7</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>ACC</td>\n",
       "      <td>0</td>\n",
       "      <td>Exploits</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>CON</td>\n",
       "      <td>2</td>\n",
       "      <td>Exploits</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23472</th>\n",
       "      <td>RST</td>\n",
       "      <td>8</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49080</th>\n",
       "      <td>CLO</td>\n",
       "      <td>1</td>\n",
       "      <td>Reconnaissance</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  state_encoded      attack_cat  attack_cat_encoded service  \\\n",
       "0       INT              5          Normal                   6       -   \n",
       "29      FIN              4          Normal                   6       -   \n",
       "52      REQ              7          Normal                   6       -   \n",
       "458     ACC              0        Exploits                   3       -   \n",
       "555     CON              2        Exploits                   3       -   \n",
       "23472   RST              8          Normal                   6       -   \n",
       "49080   CLO              1  Reconnaissance                   7       -   \n",
       "\n",
       "       service_encoded  \n",
       "0                    0  \n",
       "29                   0  \n",
       "52                   0  \n",
       "458                  0  \n",
       "555                  0  \n",
       "23472                0  \n",
       "49080                0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_subset = testing.loc[:, ['state','state_encoded','attack_cat','attack_cat_encoded','service','service_encoded']]\n",
    "testing_subset[~testing_subset.duplicated('state')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 43\n",
    "hidden_size = 64      # 1st layer number of neurons\n",
    "hidden_size_2 = 64    # 2nd layer number of neurons\n",
    "num_classes = 10      # There are 9 different types of malicious packets + Normal\n",
    "\n",
    "num_epochs = 40\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_total_steps = len(x_training)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=43, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (droput): Dropout(p=0.2)\n",
      "  (relu): ReLU()\n",
      "  (elu): ELU(alpha=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size, hidden_size, hidden_size_2, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 44], m2: [43 x 64] at /opt/conda/conda-bld/pytorch_1556653099582/work/aten/src/TH/generic/THTensorMath.cpp:961",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-4ac6e0c69aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-07e8e63adfb9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#x is the input tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#add hidden layer, with relu activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 44], m2: [43 x 64] at /opt/conda/conda-bld/pytorch_1556653099582/work/aten/src/TH/generic/THTensorMath.cpp:961"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "   \n",
    "    for i in range(0, x_training.shape[0], batch_size):\n",
    "\n",
    "\n",
    "        x = torch.as_tensor(x_training[i:i+batch_size], dtype=torch.float).to(device)\n",
    "        y = torch.as_tensor(y_training[i:i+batch_size], dtype=torch.long).to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 55.134636172616084 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0  \n",
    "    for i in range(0, x_testing.shape[0], batch_size):\n",
    "        x = torch.as_tensor(x_testing[i:i+batch_size], dtype=torch.float).to(device)\n",
    "        y = torch.as_tensor(y_testing[i:i+batch_size], dtype=torch.long).to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "        if len(outputs.data) > 0:\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            n_samples += y.size(0)\n",
    "            n_correct += (predicted == y).sum().item()\n",
    "        else:\n",
    "            print(\"what???\")\n",
    "            print(x, outputs.data)\n",
    "    acc = 100.0 * n_correct / (n_samples+1)\n",
    "    print(f'Accuracy of the network: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with an auto-encoder ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
