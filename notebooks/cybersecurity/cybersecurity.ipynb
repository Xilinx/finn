{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#needed to create the Neural Network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#general\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspired by [this github file](https://github.com/alik604/cyber-security/blob/master/Intrusion-Detection/UNSW_NB15%20-%20Torch%20MLP%20and%20autoEncoder.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get UNSW_NB15 train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_training-set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_testing-set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define UNSW_NB15 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNSW_NB15(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, sequence_length=25, transform=None):\n",
    "        #TODO have a sequence_overlap=True flag? Does overlap matter?\n",
    "        self.transform = transform\n",
    "        self.sequence_length = sequence_length\n",
    "        self.columns = ['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
    "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
    "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
    "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
    "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
    "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
    "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
    "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n",
    "        self.dtypes = dtypes = {\"id\":\"int32\",\n",
    "                                \"scrip\": \"string\",\n",
    "                                #\"sport\": \"int32\",\n",
    "                                \"dstip\": \"string\",\n",
    "                                #\"dsport\": \"int32\",\n",
    "                                \"proto\": \"string\",\n",
    "                                \"state\": \"string\",\n",
    "                                \"dur\": \"float64\",\n",
    "                                \"sbytes\": \"int32\",\n",
    "                                \"dbytes\": \"int32\",\n",
    "                                \"sttl\": \"int32\",\n",
    "                                \"dttl\": \"int32\",\n",
    "                                \"sloss\": \"int32\",\n",
    "                                \"dloss\": \"int32\",\n",
    "                                \"service\": \"string\",\n",
    "                                \"sload\": \"float64\",\n",
    "                                \"dload\": \"float64\",\n",
    "                                \"spkts\": \"int32\",\n",
    "                                \"dpkts\": \"int32\",\n",
    "                                \"swin\": \"int32\",\n",
    "                                \"dwin\": \"int32\",\n",
    "                                \"stcpb\": \"int32\",\n",
    "                                \"dtcpb\": \"int32\", \n",
    "                                #\"smeansz\": \"int32\",\n",
    "                                #\"dmeansz\": \"int32\",\n",
    "                                \"trans_depth\": \"int32\",\n",
    "                                #\"res_bdy_len\": \"int32\",\n",
    "                                \"sjit\": \"float64\",\n",
    "                                \"djit\": \"float64\",\n",
    "                                #\"stime\": \"int64\",\n",
    "                                #\"ltime\": \"int64\",\n",
    "                                #\"sintpkt\": \"float64\",\n",
    "                                #\"dintpkt\": \"float64\",\n",
    "                                \"tcprtt\": \"float64\",\n",
    "                                \"synack\": \"float64\",\n",
    "                                \"ackdat\": \"float64\",\n",
    "\n",
    "                                #commenting these because they have mixed values and we aren't going to generate them anyway\n",
    "                                #\"is_sm_ips_ports\": \"int32\",\n",
    "                                #\"ct_state_ttl\": \"int32\",\n",
    "                                #\"ct_flw_httpd_mthd\": \"int32\",\n",
    "                                #\"is_ftp_login\": \"int32\",\n",
    "                                #\"is_ftp_cmd\": \"int32\",\n",
    "                                #\"ct_ftp_cmd\": \"int32\",\n",
    "                                #\"ct_srv_src\": \"int32\",\n",
    "                                ##\"ct_dst_ltm\": \"int32\", \n",
    "                                #\"ct_src_ltm\": \"int32\",\n",
    "                                #\"ct_src_dport_ltm\": \"int32\",\n",
    "                                #\"ct_dst_sport_ltm\": \"int32\",\n",
    "                                #\"ct_dst_src_ltm\": \"int32\",\n",
    "                                \"attack_cat\": \"string\",\n",
    "                                \"label\": \"int32\"}\n",
    "        self.categorical_column_values = {\"proto\":None, \"state\":None, \"service\":None, \"attack_cat\":None}\n",
    "\n",
    "        self.dataframe = pd.read_csv(file_path, encoding=\"latin-1\", names=self.columns,header=0, dtype=self.dtypes)\n",
    "        #self.dataframe.sort_values(by=['stime']) #sort chronologically upon loading\n",
    "        \n",
    "        #load all the unique values of categorical features at the start\n",
    "        #and make these accessible via a fast function call.\n",
    "        for key in self.categorical_column_values:\n",
    "            self.categorical_column_values[key] = self.dataframe[key].unique()\n",
    "\n",
    "        #cache all the maximum values in numeric columns since we'll be using these for feature extraction\n",
    "        self.maximums = {}\n",
    "        for key in self.dtypes:\n",
    "            if \"int\" in self.dtypes[key] or \"float\" in self.dtypes[key]:\n",
    "                self.maximums[key] = max(self.dataframe[key])\n",
    "        \n",
    "        #------------------------------------------------\n",
    "        self.dataframe = self.dataframe.drop(['id'],1)\n",
    "               \n",
    "       \n",
    "        ##------Encoding string columns with value between 0 and n_classes-1----\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        self.dataframe['attack_cat'] = le.fit_transform(self.dataframe['attack_cat'])\n",
    "        self.dataframe['proto'] = le.fit_transform(self.dataframe['proto'])\n",
    "        self.dataframe['service'] = le.fit_transform(self.dataframe['service'])\n",
    "        self.dataframe['state'] = le.fit_transform(self.dataframe['state'])\n",
    "        \n",
    "        # ----------Normalising all numerical features--------------\n",
    "        #cols_to_normalise = list(self.dataframe.columns.values)[:39]\n",
    "        #self.dataframe[cols_to_normalise] = self.dataframe[cols_to_normalise].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        #self.dataframe[cols_to_normalise] = self.dataframe[cols_to_normalise].apply(lambda x: (x - x.min()) / (x.max() - x.min()))               \n",
    "        \n",
    "        #-----------Create pytorch tensor----------------\n",
    "        self.tensor = torch.Tensor(self.dataframe.values)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_tensor(self):\n",
    "        return self.tensor\n",
    "    \n",
    "    def get_dataframe(self):\n",
    "        return self.dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe.index) - self.sequence_length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #TODO need error checking for out of bounds?\n",
    "        #TODO return x,y where y is the category of the example\n",
    "        #since none corresponds to \"normal\" data\n",
    "        \n",
    "        list_of_dicts = []\n",
    "        for i in range(index,index+self.sequence_length):\n",
    "            list_of_dicts.append(self.dataframe.loc[i, :].to_dict())\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            return self.transform(self, list_of_dicts)\n",
    "        \n",
    "        return list_of_dicts\n",
    "    \n",
    "    #get a list of all the unique labels in the dataset\n",
    "    def get_labels(self):\n",
    "        return self.dataframe['label'].unique().tolist()\n",
    "    \n",
    "    #get a list of all the unique attack categories in the dataset\n",
    "    def get_attack_categories(self):\n",
    "        return self.dataframe['attack_cat'].unique().tolist()\n",
    "    \n",
    "    def get_list_of_categories(self, column_name):\n",
    "        pass #TODO\n",
    "\n",
    "    #limit the dataset to only examples in the specified category\n",
    "    def use_only_category(self, category_name):\n",
    "        if category_name not in self.get_attack_categories():\n",
    "            return False\n",
    "        \n",
    "        new_dataframe = self.dataframe[self.dataframe['attack_cat'] == category_name]\n",
    "        new_dataframe = new_dataframe.reset_index()\n",
    "        self.dataframe = new_dataframe\n",
    "        return True\n",
    "    \n",
    "    #limit the dataset to only examples with the specified label\n",
    "    def use_only_label(self, label):\n",
    "        if label not in self.get_labels():\n",
    "            return False\n",
    "        \n",
    "        new_dataframe = self.dataframe[self.dataframe['label'] == label]\n",
    "        new_dataframe = new_dataframe.reset_index()\n",
    "        self.dataframe = new_dataframe\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size_2, num_classes):\n",
    "        super(Net,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        # linear layer (input_size -> hidden_size)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # linear layer (hidden_size -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size_2)\n",
    "        # linear layer (hidden_size_2 -> num_classes)\n",
    "        self.fc3 = nn.Linear(hidden_size_2, num_classes)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.droput = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.elu = nn.ELU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #x is the input tensor\n",
    "        out = self.fc1(x)\n",
    "        #add hidden layer, with relu activation function\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # add hidden layer, with relu activation function\n",
    "        out = self.relu(out)\n",
    "        # add dropout instead of relu or not..?\n",
    "        #out = self.droput(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize UNSW_NB15 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>ackdat</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.121478</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>172</td>\n",
       "      <td>74.087490</td>\n",
       "      <td>252</td>\n",
       "      <td>254</td>\n",
       "      <td>14158.942380</td>\n",
       "      <td>8495.365234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.295600</td>\n",
       "      <td>8.375000</td>\n",
       "      <td>30.177547</td>\n",
       "      <td>11.830604</td>\n",
       "      <td>255</td>\n",
       "      <td>621772692</td>\n",
       "      <td>-2092433665</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649902</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>734</td>\n",
       "      <td>42014</td>\n",
       "      <td>78.473372</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>8395.112305</td>\n",
       "      <td>503571.312500</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>49.915000</td>\n",
       "      <td>15.432865</td>\n",
       "      <td>61.426934</td>\n",
       "      <td>1387.778330</td>\n",
       "      <td>255</td>\n",
       "      <td>1417884146</td>\n",
       "      <td>-1217579325</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.623129</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>364</td>\n",
       "      <td>13186</td>\n",
       "      <td>14.170161</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>1572.271851</td>\n",
       "      <td>60929.230470</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>231.875571</td>\n",
       "      <td>102.737203</td>\n",
       "      <td>17179.586860</td>\n",
       "      <td>11420.926230</td>\n",
       "      <td>255</td>\n",
       "      <td>2116150707</td>\n",
       "      <td>-1331852323</td>\n",
       "      <td>255</td>\n",
       "      <td>0.111897</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.050439</td>\n",
       "      <td>46</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.681642</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>62</td>\n",
       "      <td>252</td>\n",
       "      <td>2740.178955</td>\n",
       "      <td>3358.622070</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>152.876547</td>\n",
       "      <td>90.235726</td>\n",
       "      <td>259.080172</td>\n",
       "      <td>4991.784669</td>\n",
       "      <td>255</td>\n",
       "      <td>1107119177</td>\n",
       "      <td>1047442890</td>\n",
       "      <td>255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449454</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>534</td>\n",
       "      <td>268</td>\n",
       "      <td>33.373826</td>\n",
       "      <td>254</td>\n",
       "      <td>252</td>\n",
       "      <td>8561.499023</td>\n",
       "      <td>3987.059814</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47.750333</td>\n",
       "      <td>75.659602</td>\n",
       "      <td>2415.837634</td>\n",
       "      <td>115.807000</td>\n",
       "      <td>255</td>\n",
       "      <td>-1858829747</td>\n",
       "      <td>1977154190</td>\n",
       "      <td>255</td>\n",
       "      <td>0.128381</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.057234</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
       "0  0.121478    113        0      2      6      4     258     172  74.087490   \n",
       "1  0.649902    113        0      2     14     38     734   42014  78.473372   \n",
       "2  1.623129    113        0      2      8     16     364   13186  14.170161   \n",
       "3  1.681642    113        3      2     12     12     628     770  13.677108   \n",
       "4  0.449454    113        0      2     10      6     534     268  33.373826   \n",
       "\n",
       "   sttl  dttl         sload          dload  sloss  dloss      sinpkt  \\\n",
       "0   252   254  14158.942380    8495.365234      0      0   24.295600   \n",
       "1    62   252   8395.112305  503571.312500      2     17   49.915000   \n",
       "2    62   252   1572.271851   60929.230470      1      6  231.875571   \n",
       "3    62   252   2740.178955    3358.622070      1      3  152.876547   \n",
       "4   254   252   8561.499023    3987.059814      2      1   47.750333   \n",
       "\n",
       "       dinpkt          sjit          djit  swin       stcpb       dtcpb  dwin  \\\n",
       "0    8.375000     30.177547     11.830604   255   621772692 -2092433665   255   \n",
       "1   15.432865     61.426934   1387.778330   255  1417884146 -1217579325   255   \n",
       "2  102.737203  17179.586860  11420.926230   255  2116150707 -1331852323   255   \n",
       "3   90.235726    259.080172   4991.784669   255  1107119177  1047442890   255   \n",
       "4   75.659602   2415.837634    115.807000   255 -1858829747  1977154190   255   \n",
       "\n",
       "     tcprtt    synack    ackdat  smean  dmean  trans_depth  response_body_len  \\\n",
       "0  0.000000  0.000000  0.000000     43     43            0                  0   \n",
       "1  0.000000  0.000000  0.000000     52   1106            0                  0   \n",
       "2  0.111897  0.061458  0.050439     46    824            0                  0   \n",
       "3  0.000000  0.000000  0.000000     52     64            0                  0   \n",
       "4  0.128381  0.071147  0.057234     53     45            0                  0   \n",
       "\n",
       "   ct_srv_src  ct_state_ttl  ct_dst_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  \\\n",
       "0           1             0           1                 1                 1   \n",
       "1          43             1           1                 1                 1   \n",
       "2           7             1           2                 1                 1   \n",
       "3           1             1           2                 1                 1   \n",
       "4          43             1           2                 2                 1   \n",
       "\n",
       "   ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  \\\n",
       "0               1             0           0                 0           1   \n",
       "1               2             0           0                 0           1   \n",
       "2               3             0           0                 0           2   \n",
       "3               3             1           1                 0           2   \n",
       "4              40             0           0                 0           2   \n",
       "\n",
       "   ct_srv_dst  is_sm_ips_ports  attack_cat  label  \n",
       "0           1                0           6      0  \n",
       "1           6                0           6      0  \n",
       "2           6                0           6      0  \n",
       "3           1                0           6      0  \n",
       "4          39                0           6      0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsw_nb15_training = UNSW_NB15(file_path ='UNSW_NB15_training-set.csv')\n",
    "training = unsw_nb15_training.get_dataframe()\n",
    "x_training = training.iloc[:, 0:-1].values\n",
    "y_training = training.iloc[:, -1].values # Last two (or 1 ?) columns are categories and labels\n",
    "\n",
    "\n",
    "unsw_nb15_testing = UNSW_NB15(file_path ='UNSW_NB15_testing-set.csv')\n",
    "testing = unsw_nb15_testing.get_dataframe()\n",
    "x_testing = testing.iloc[:, 0:-1].values\n",
    "y_testing = testing.iloc[:, -1].values # Last two (or 1 ?) columns are categories and labels\n",
    "\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 43\n",
    "hidden_size = 64      # 1st layer number of neurons\n",
    "hidden_size_2 = 64    # 2nd layer number of neurons\n",
    "num_classes = 10      # There are 9 different types of malicious packets + Normal\n",
    "\n",
    "num_epochs = 40\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_total_steps = len(x_training)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=43, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (droput): Dropout(p=0.2)\n",
      "  (relu): ReLU()\n",
      "  (elu): ELU(alpha=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size, hidden_size, hidden_size_2, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40], Step [175329/175341], Loss: 0.0527\n",
      "Epoch [20/40], Step [175329/175341], Loss: 0.0519\n",
      "Epoch [30/40], Step [175329/175341], Loss: 0.0528\n",
      "Epoch [40/40], Step [175329/175341], Loss: 0.0528\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "   \n",
    "    for i in range(0, x_training.shape[0], batch_size):\n",
    "\n",
    "\n",
    "        x = torch.as_tensor(x_training[i:i+batch_size], dtype=torch.float).to(device)\n",
    "        y = torch.as_tensor(y_training[i:i+batch_size], dtype=torch.long).to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 55.134636172616084 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0  \n",
    "    for i in range(0, x_testing.shape[0], batch_size):\n",
    "        x = torch.as_tensor(x_testing[i:i+batch_size], dtype=torch.float).to(device)\n",
    "        y = torch.as_tensor(y_testing[i:i+batch_size], dtype=torch.long).to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "        if len(outputs.data) > 0:\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            n_samples += y.size(0)\n",
    "            n_correct += (predicted == y).sum().item()\n",
    "        else:\n",
    "            print(\"what???\")\n",
    "            print(x, outputs.data)\n",
    "    acc = 100.0 * n_correct / (n_samples+1)\n",
    "    print(f'Accuracy of the network: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with an auto-encoder ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
