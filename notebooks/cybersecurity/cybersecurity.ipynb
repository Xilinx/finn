{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#!pip install --user pandas\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "from dataloader import UNSW_NB15\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspired by [this github file](https://github.com/alik604/cyber-security/blob/master/Intrusion-Detection/UNSW_NB15%20-%20Torch%20MLP%20and%20autoEncoder.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get UNSW_NB15 train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_training-set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/a%20part%20of%20training%20and%20testing%20set/UNSW_NB15_testing-set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN architecture\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size,hidden1, hidden2, hidden3, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden2, hidden3)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(hidden3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.out = nn.Linear(hidden3, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a1 = self.fc1(x)\n",
    "        #b1 = self.batchnorm1(a1)\n",
    "        h1 = self.relu1(a1)\n",
    "        dout1 = self.dout(h1)\n",
    "        \n",
    "        a2 = self.fc2(dout1)\n",
    "        #b2 = self.batchnorm2(a2)\n",
    "        h2 = self.relu2(a2)\n",
    "        dout2 = self.dout(h2)\n",
    "        \n",
    "        a3 = self.fc3(dout2)\n",
    "        #b3 = self.batchnorm3(a3)\n",
    "        h3 = self.relu3(a3)\n",
    "        dout3 = self.dout(h3)\n",
    "        \n",
    "        a4= self.out(dout3)\n",
    "        y = self.sigmoid(a4)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train,   Test   and    Display_Loss_Plot    methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, target ( or labels)]\n",
    "        inputs , target = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #MOVING THE TENSORS TO THE CONFIGURED DEVICE\n",
    "        #inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        #FORWARD PASS\n",
    "        output = model(inputs.float())\n",
    "\n",
    "        loss = criterion(output, target.unsqueeze(1))\n",
    "        #import pdb; pdb.set_trace()\n",
    "        \n",
    "        #BACKWARD AND OPTIMIZE\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # PREDICTIONS\n",
    "        #pred = np.round(output.detach().numpy())\n",
    "        pred = output.detach().numpy() > 0.5  \n",
    "        target = target.float()\n",
    "        y_true.extend(target.tolist()) \n",
    "        y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "        losses.append(loss.data.numpy()) \n",
    "    #print(\"Accuracy on training set is\" , accuracy_score(y_true,y_pred))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING THE MODEL\n",
    "def test(model, device, test_loader):\n",
    "    #model in eval mode skips Dropout etc\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            \n",
    "            #LOAD THE DATA IN A BATCH\n",
    "            inputs ,target = data\n",
    "            \n",
    "            # the model on the data\n",
    "            output = model(inputs.float())\n",
    "                       \n",
    "            #PREDICTIONS\n",
    "            pred = np.round(output)\n",
    "            #pred = output.detach().numpy() > 0.5 \n",
    "            pred = pred * 1\n",
    "            target = target.float()\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_loss_plot(losses):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title('Loss of the model')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('Cross entropy loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "input_size = 196      # 42 for integer encoding 196\n",
    "hidden1 = 128      # 1st layer number of neurons\n",
    "hidden2 = 64\n",
    "hidden3 = 32\n",
    "num_classes = 1    # binary classification\n",
    "\n",
    "num_epochs = 1000  #500 1000 100 100\n",
    "batch_size = 500   #100 1000 100 500  \n",
    "lr = 0.01          #0.01 0.01 0.005 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_size, hidden1, hidden2, hidden3, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize UNSW_NB15 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are not slitted into validation and train set\n",
    "train_dataset = UNSW_NB15(file_path ='UNSW_NB15_training-set.csv')\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#get the test dataframe\n",
    "test_dataset = UNSW_NB15(file_path ='UNSW_NB15_testing-set.csv')\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train, Test the model and see the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "running_loss = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "        loss_epoch = train(model, device, train_loader, optimizer,criterion)\n",
    "        running_loss.append(loss_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    num_epochs = 200\n",
    "    batch_size = 8000 \n",
    "    lr = 0.001\n",
    "    accuracy on test set = 0.7572389836272653\n",
    "<img src=\"data/loss_function_75.723898_acc.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quntization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def integer_encoding(df_):\n",
    "    df = df_.copy()\n",
    "    \"\"\"Applies integer encoding to the object columns of the dataframe\"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    for column in df.select_dtypes('object').columns.tolist():\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from here https://stackoverflow.com/questions/51471097/vectorized-conversion-of-decimal-integer-array-to-binary-array-in-numpy\n",
    "def dec2bin(column: pd.Series, number_of_bits: int, left_msb:bool= True )-> pd.Series: \n",
    "    \"\"\"Convert a decimal pd.Series to binary pd.Series with numbers in their base-2 equivalents.\n",
    "    The output is a numpy nd array.   \n",
    "    # adapted from here https://stackoverflow.com/questions/51471097/vectorized-conversion-of-decimal-integer-array-to-binary-array-in-numpy\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "     column: pd.Series\n",
    "        Series wit all decimal numbers that will be cast to binary\n",
    "     number_of_bits: str\n",
    "        The desired number of bits for the binary number. If bigger than what is needed then those bits will be 0.\n",
    "        The number_of_bits should be >= than what is needed to express the largest decimal input \n",
    "     left_msb: bool\n",
    "        Specify that the most significant digit is the leftmost element. If this is False, it will be the rightmost element.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "       Numpy array with all elements in binary representation of the input.\n",
    "        \n",
    "    \"\"\"\n",
    " \n",
    "    my_binary_repr = lambda number, nbits:  np.binary_repr(number, nbits)[::-1]\n",
    "    func = my_binary_repr if left_msb else np.binary_repr\n",
    " \n",
    "    return np.vectorize(func)(column.values, number_of_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dataset and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/UNSW_NB15_training-set.csv', sep = \",\")\n",
    "test = pd.read_csv('data/UNSW_NB15_testing-set.csv', sep = \",\")\n",
    "\n",
    "df = pd.concat([test,train],ignore_index=True)\n",
    "skip_cols = ['id','attack_cat'] #this is what they have\n",
    "binary_matrix = None # final matrix of bit vetors\n",
    "first_iteration = True\n",
    "\n",
    "# gets the smallest positive number of a vector\n",
    "get_min_positive_number = lambda vector: vector[vector > 0].min()\n",
    "# computes the maximum required bits to represent eachs number from a vector of numbers\n",
    "get_max_bits = lambda vector: math.ceil(math.log2(vector.max()+1))\n",
    "\n",
    "df = integer_encoding(df) #perform integer encoding on the string columns just as they do\n",
    "total_bits = 0\n",
    "for idx, column in enumerate(df.columns):\n",
    "    if column not in skip_cols:\n",
    "        m = get_min_positive_number(df[column])\n",
    "        m = 1/m\n",
    "       \n",
    "        if m>1:\n",
    "            df[column] = df[column] * m\n",
    "        maxbits = get_max_bits(df[column])\n",
    "        total_bits += maxbits\n",
    "        #print(str(idx), \" : \", str(total_bits))\n",
    "        binary_vector = dec2bin(df[column].astype(np.uint32), maxbits, left_msb=False).reshape((-1,1))\n",
    "        if first_iteration:\n",
    "            binary_matrix = binary_vector\n",
    "            first_iteration = False\n",
    "        else:\n",
    "            binary_matrix = np.hstack([binary_matrix, binary_vector])\n",
    "\n",
    "id_= round((2*binary_matrix.shape[0])/3)\n",
    "id6 = round((2*binary_matrix.shape[0])/3/6)\n",
    "\n",
    "infeat_train = binary_matrix[0:id_-id6,:]\n",
    "infeat_valid = binary_matrix[(id_-id6+1):id_,:]\n",
    "infeat_test  = binary_matrix[id_+1:,:]\n",
    "\n",
    "infeat_train = infeat_train[0:round(infeat_train.shape[0]/10),:];\n",
    "infeat_valid = infeat_valid[0:round(infeat_valid.shape[0]/10),:];\n",
    "infeat_test  = infeat_test[0:round(infeat_test.shape[0]/10),:]\n",
    "\n",
    "np.savetxt(\"fds_unswb15_train_python.csv\", infeat_train, fmt=\"%s\",delimiter=\"\")\n",
    "np.savetxt('fds_unswb15_valid_python.csv', infeat_valid, fmt=\"%s\",delimiter=\"\")\n",
    "np.savetxt('fds_unswb15_test_python.csv', infeat_test, fmt=\"%s\",delimiter=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
       "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
       "\n",
       "          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0   90909.0902  ...                 1               2             0   \n",
       "1  125000.0003  ...                 1               2             0   \n",
       "\n",
       "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0           0                 0           1           2                0   \n",
       "1           0                 0           1           2                0   \n",
       "\n",
       "   attack_cat  label  \n",
       "0      Normal      0  \n",
       "1      Normal      0  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/UNSW_NB15_training-set.csv', sep = \",\")\n",
    "test = pd.read_csv('data/UNSW_NB15_testing-set.csv', sep = \",\")\n",
    "\n",
    "df = pd.concat([test,train])\n",
    "skip_cols = ['id','attack_cat'] #this is what they have\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>sinpkt</th>\n",
       "      <th>dinpkt</th>\n",
       "      <th>sjit</th>\n",
       "      <th>djit</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>dwin</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>ackdat</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>1.803636e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>8.810000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>8.544000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>8.504000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>784</td>\n",
       "      <td>0</td>\n",
       "      <td>333333.3215</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>1.045333e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.000011    119        0      5      2      0     496       0   \n",
       "1   2  0.000008    119        0      5      2      0    1762       0   \n",
       "2   3  0.000005    119        0      5      2      0    1068       0   \n",
       "3   4  0.000006    119        0      5      2      0     900       0   \n",
       "4   5  0.000010    119        0      5      2      0    2126       0   \n",
       "5   6  0.000003    119        0      5      2      0     784       0   \n",
       "\n",
       "          rate  sttl  dttl         sload  dload  sloss  dloss  sinpkt  dinpkt  \\\n",
       "0   90909.0902   254     0  1.803636e+08    0.0      0      0   0.011     0.0   \n",
       "1  125000.0003   254     0  8.810000e+08    0.0      0      0   0.008     0.0   \n",
       "2  200000.0051   254     0  8.544000e+08    0.0      0      0   0.005     0.0   \n",
       "3  166666.6608   254     0  6.000000e+08    0.0      0      0   0.006     0.0   \n",
       "4  100000.0025   254     0  8.504000e+08    0.0      0      0   0.010     0.0   \n",
       "5  333333.3215   254     0  1.045333e+09    0.0      0      0   0.003     0.0   \n",
       "\n",
       "   sjit  djit  swin  stcpb  dtcpb  dwin  tcprtt  synack  ackdat  smean  dmean  \\\n",
       "0   0.0   0.0     0      0      0     0     0.0     0.0     0.0    248      0   \n",
       "1   0.0   0.0     0      0      0     0     0.0     0.0     0.0    881      0   \n",
       "2   0.0   0.0     0      0      0     0     0.0     0.0     0.0    534      0   \n",
       "3   0.0   0.0     0      0      0     0     0.0     0.0     0.0    450      0   \n",
       "4   0.0   0.0     0      0      0     0     0.0     0.0     0.0   1063      0   \n",
       "5   0.0   0.0     0      0      0     0     0.0     0.0     0.0    392      0   \n",
       "\n",
       "   trans_depth  response_body_len  ct_srv_src  ct_state_ttl  ct_dst_ltm  \\\n",
       "0            0                  0           2             2           1   \n",
       "1            0                  0           2             2           1   \n",
       "2            0                  0           3             2           1   \n",
       "3            0                  0           3             2           2   \n",
       "4            0                  0           3             2           2   \n",
       "5            0                  0           2             2           2   \n",
       "\n",
       "   ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0                 1                 1               2             0   \n",
       "1                 1                 1               2             0   \n",
       "2                 1                 1               3             0   \n",
       "3                 2                 1               3             0   \n",
       "4                 2                 1               3             0   \n",
       "5                 2                 1               2             0   \n",
       "\n",
       "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0           0                 0           1           2                0   \n",
       "1           0                 0           1           2                0   \n",
       "2           0                 0           1           3                0   \n",
       "3           0                 0           2           3                0   \n",
       "4           0                 0           2           3                0   \n",
       "5           0                 0           2           2                0   \n",
       "\n",
       "   attack_cat  label  \n",
       "0           6      0  \n",
       "1           6      0  \n",
       "2           6      0  \n",
       "3           6      0  \n",
       "4           6      0  \n",
       "5           6      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = integer_encoding(df)\n",
    "df_encoded.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dur  :  26\n",
      "proto  :  34\n",
      "service  :  38\n",
      "state  :  42\n",
      "spkts  :  56\n",
      "dpkts  :  70\n",
      "sbytes  :  94\n",
      "dbytes  :  118\n",
      "rate  :  148\n",
      "sttl  :  156\n",
      "dttl  :  164\n",
      "sload  :  198\n",
      "dload  :  223\n",
      "sloss  :  236\n",
      "dloss  :  249\n",
      "sinpkt  :  276\n",
      "dinpkt  :  302\n",
      "sjit  :  333\n",
      "djit  :  359\n",
      "swin  :  367\n",
      "stcpb  :  399\n",
      "dtcpb  :  431\n",
      "dwin  :  439\n",
      "tcprtt  :  453\n",
      "synack  :  466\n",
      "ackdat  :  482\n",
      "smean  :  493\n",
      "dmean  :  504\n",
      "trans_depth  :  512\n",
      "response_body_len  :  535\n",
      "ct_srv_src  :  541\n",
      "ct_state_ttl  :  544\n",
      "ct_dst_ltm  :  550\n",
      "ct_src_dport_ltm  :  556\n",
      "ct_dst_sport_ltm  :  562\n",
      "ct_dst_src_ltm  :  569\n",
      "is_ftp_login  :  572\n",
      "ct_ftp_cmd  :  575\n",
      "ct_flw_http_mthd  :  580\n",
      "ct_src_ltm  :  586\n",
      "ct_srv_dst  :  592\n",
      "is_sm_ips_ports  :  593\n",
      "label  :  594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(257673, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the smallest positive number of a vector\n",
    "get_min_positive_number = lambda vector: vector[vector > 0].min()\n",
    "# computes the maximum required bits to represent eachs number from a vector of numbers\n",
    "get_max_bits = lambda vector: math.ceil(math.log2(float(vector.max())+1.0))\n",
    "\n",
    "binarized_dataset = pd.DataFrame(columns= df_encoded.columns) # final matrix of bit vetors\n",
    "first_iteration = True\n",
    "\n",
    "binarized_dataset = df_encoded.copy()\\\n",
    "                                .drop(columns=skip_cols)\n",
    "total_bits = 0\n",
    "column_bit_position = []\n",
    "for column in binarized_dataset.columns:\n",
    "        \n",
    "    column_data = df_encoded[column]\n",
    "    \n",
    "    m = get_min_positive_number(column_data)\n",
    "    m = 1/m\n",
    "\n",
    "    if m>1:\n",
    "        column_data = column_data * m\n",
    "        \n",
    "    maxbits = get_max_bits(column_data)\n",
    "    total_bits += maxbits\n",
    "    column_bit_position.append([column, total_bits])\n",
    "    print(column, \" : \", total_bits)\n",
    "    binary_vector = dec2bin(column_data.astype('int64'), maxbits, left_msb=False).reshape((-1,1))\n",
    "    binarized_dataset[column] = binary_vector.flatten()\n",
    "    \n",
    "\n",
    "#Merge the columns\n",
    "binarized_dataset_concated = binarized_dataset.apply(lambda row: \"\".join(row),axis=1).values.reshape((-1,1))\n",
    "binarized_dataset_concated.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the entire dataset quantized from matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257673, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binfeat = pd.read_csv('binfeat.csv',header=None).values\n",
    "binfeat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22683"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of correct columns is 22 683 out of 257 673 total\n",
    "(binfeat == binarized_dataset_concated).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[147, 197]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this outputs the bit position(s) that is different between each row\n",
    "check_diff(binarized_dataset_concated[1][0], binfeat[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarized_dataset_concated == binfeat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_diff(a : str, b : str) -> List[int]:\n",
    "    \"\"\"\n",
    "    return the positions where a != b\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    assert len(a) == len(b), f\"the two strings must have equal size. len(a)={len(a)}, len(b)={len(b)}\"\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "            result.append(i)\n",
    "    return result\n",
    "\n",
    "def multi_check_diff(A,B):\n",
    "    assert A.shape == B.shape, f\"Both matrices must match in shape. A shape is {A.shape}, B shape is {B.shape}\"\n",
    "    \n",
    "    all_diffs = []\n",
    "    for i in range(A.shape[0]):\n",
    "        all_diffs.append(check_diff(A[i][0], B[i][0]))\n",
    "    return all_diffs\n",
    "\n",
    "all_diffs = multi_check_diff(binfeat, binarized_dataset_concated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belongs_to_column(num : int, col_positions : List[List]):\n",
    "    \"\"\"\n",
    "    given any index position, returns the column that contains the bit of that position.\n",
    "    \"\"\"\n",
    "    for i in range(len(col_positions)):\n",
    "        if num < col_positions[i][1]:\n",
    "            return col_positions[i]\n",
    "\n",
    "# test -> should return rate, 148\n",
    "assert belongs_to_column(147, column_bit_position) == ['rate', 148], \"Function is failing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dur': 19767,\n",
       " 'synack': 44653,\n",
       " 'tcprtt': 56206,\n",
       " 'dinpkt': 60614,\n",
       " 'djit': 61157,\n",
       " 'dload': 64548,\n",
       " 'sjit': 65455,\n",
       " 'ackdat': 65600,\n",
       " 'sinpkt': 68599,\n",
       " 'sload': 137611,\n",
       " 'rate': 147115}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def error_row_column_distribution(all_diffs : List[List], col_positions : List[List]):\n",
    "    \"\"\"\n",
    "    For each row, counts the errors of each column. \n",
    "    One or more errors per row for the same column are counted as just +1\n",
    "    \"\"\"\n",
    "    count_dictionary = {} # key -> bit position starting from last ; value -> count of errors in this position\n",
    "    for diffs in all_diffs:\n",
    "        row_column_errors = []\n",
    "        for diff in diffs:\n",
    "            column, last_pos = belongs_to_column(diff, col_positions)\n",
    "            if column in row_column_errors:\n",
    "                continue\n",
    "            row_column_errors.append(column)\n",
    "            \n",
    "            if column not in count_dictionary:\n",
    "                count_dictionary[column] = 1\n",
    "            else:\n",
    "                count_dictionary[column] += 1\n",
    "    \n",
    "    sorted_count = {k:v for k,v in sorted(count_dictionary.items(), key = lambda item: item[1])}\n",
    "    return sorted_count\n",
    "error_row_column_distribution(all_diffs, column_bit_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \t\"rate has at least 1 errors in each of the 147k rows\"\n",
    "        \"The only columns that have bit errors are: rate, sload, sinpkt, ackdat, sjit,dload,djit,dinpkt,tcprtt,synack, dur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dur': 39401,\n",
       " 'synack': 88830,\n",
       " 'tcprtt': 111338,\n",
       " 'dinpkt': 116937,\n",
       " 'djit': 121746,\n",
       " 'dload': 128502,\n",
       " 'sjit': 129785,\n",
       " 'ackdat': 130098,\n",
       " 'sinpkt': 132801,\n",
       " 'rate': 261290,\n",
       " 'sload': 332609}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def error_bit_column_distribution(all_diffs : List[List], col_positions : List[List]):\n",
    "    count_dictionary = {} # key -> bit position starting from last ; value -> count of errors in this position\n",
    "    for diffs in all_diffs:\n",
    "        for diff in diffs:\n",
    "            column, last_pos = belongs_to_column(diff, col_positions)\n",
    "            \n",
    "            if column not in count_dictionary:\n",
    "                count_dictionary[column] = 1\n",
    "            else:\n",
    "                count_dictionary[column] += 1\n",
    "    \n",
    "    sorted_count = {k:v for k,v in sorted(count_dictionary.items(), key = lambda item: item[1])}\n",
    "    return sorted_count\n",
    "error_bit_column_distribution(all_diffs, column_bit_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    sload column has a total of 332k errors\n",
    "    rate column has a total of 261k errors\n",
    "    sinpkt column has a total of 132k errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{33: 12,\n",
       " 20: 70,\n",
       " 17: 73,\n",
       " 28: 83,\n",
       " 23: 88,\n",
       " 24: 90,\n",
       " 25: 91,\n",
       " 22: 95,\n",
       " 21: 95,\n",
       " 14: 104,\n",
       " 30: 105,\n",
       " 18: 112,\n",
       " 26: 118,\n",
       " 27: 120,\n",
       " 31: 121,\n",
       " 19: 122,\n",
       " 29: 124,\n",
       " 13: 124,\n",
       " 16: 126,\n",
       " 15: 139,\n",
       " 32: 177,\n",
       " 12: 223,\n",
       " 11: 310,\n",
       " 10: 526,\n",
       " 9: 1076,\n",
       " 8: 2281,\n",
       " 7: 13485,\n",
       " 6: 18221,\n",
       " 5: 27707,\n",
       " 4: 48053,\n",
       " 3: 87792,\n",
       " 2: 179926,\n",
       " 1: 420322,\n",
       " 0: 791226}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def error_bit_position_distribution(all_diffs : List[List], col_positions : List[List]):\n",
    "    count_dictionary = {} # key -> bit position starting from last ; value -> count of errors in this position\n",
    "    for diffs in all_diffs:\n",
    "        for diff in diffs:\n",
    "            column, last_pos = belongs_to_column(diff, col_positions)\n",
    "            position_counting_from_last = last_pos - diff - 1\n",
    "            \n",
    "            if position_counting_from_last not in count_dictionary:\n",
    "                count_dictionary[position_counting_from_last] = 1\n",
    "            else:\n",
    "                count_dictionary[position_counting_from_last] += 1\n",
    "    \n",
    "    sorted_count = {k:v for k,v in sorted(count_dictionary.items(), key = lambda item: item[1])}\n",
    "    return sorted_count\n",
    "error_bit_position_distribution(all_diffs, column_bit_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    791k of all the errors that are made, are in the last bit\n",
    "    420k of the errors are on the second to last bit\n",
    "    179k of the errors are on the third to last bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the integer encoding. Specifically if matlab integers encodes the same way as python\n",
    "    Conclusion: Matlab integers encodes the same way as python. All category columns generated with python are integer encoded the same way as the matlab generated ones, no differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"python_train = pd.read_csv(\"fds_unswb15_train_python.csv\", header=None)\n",
    "python_valid = pd.read_csv(\"fds_unswb15_valid_python.csv\", header=None).values\n",
    "python_test = pd.read_csv(\"fds_unswb15_test_python.csv\", header=None).values\n",
    "\n",
    "matlab_train = pd.read_csv(\"fds_unswb15_train_matlab.csv\", header=None).values\n",
    "matlab_valid = pd.read_csv(\"fds_unswb15_valid_matlab.csv\", header=None).values\n",
    "matlab_test = pd.read_csv(\"fds_unswb15_test_matlab.csv\", header=None).values\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Read the category coluns from matlab in decimals\n",
    "df_c = pd.read_csv('C_3.csv', sep = ' ',header=None)\n",
    "df_c.columns = [\"a1\",\"a2\",\"proto\",\"service\",\"state\"]\n",
    "df_c.head(3)\n",
    "\n",
    "# Read the traind and testcsv files\n",
    "train = pd.read_csv('data/UNSW_NB15_training-set.csv', sep = \",\")\n",
    "test = pd.read_csv('data/UNSW_NB15_testing-set.csv', sep = \",\")\n",
    "df = pd.concat([test,train])\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['proto'] = le.fit_transform(df['proto'])\n",
    "df['service'] = le.fit_transform(df['service'])\n",
    "df['state'] = le.fit_transform(df['state'])\n",
    "#le.classes_\n",
    "df.head()\n",
    "\n",
    "print(np.array_equal(df_c[\"state\"].values, df[\"state\"].values))\n",
    "\n",
    "print(np.array_equal(df_c[\"service\"].values, df[\"service\"].values))\n",
    "\n",
    "print(np.array_equal(df_c[\"proto\"].values, df[\"proto\"].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
