{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINN Build\n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "**Important: This notebook depends on the 2-cybersecurity-finn-verification notebook and on the 1-cybersecurity-Brevitas-1bit notebook, because we are using models that were created by these notebooks. So please make sure the needed .onnx files are generated to run this notebook.**\n",
    "\n",
    "This notebook will walk you through the build flow and the model deployment into FINN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------\n",
    "1. [Define Some Necessary Parameters ](#define_param)\n",
    "2. [Build the Model](#build_model)\n",
    "3. [Explore the Build Generated Files](#explore_generated)\n",
    "\n",
    "    3.1. [Reports](#reports)  \n",
    "    3.2 [Intermediate Models ](intermediate_models#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Some Necessary Parameters <a id=\"define_param\"></a>\n",
    "\n",
    "All documentation on FINN and on the FINN build can be found [here](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html).\n",
    "First we need to define some variables: such as the model name, model file and the platform name.\n",
    "Moreover, some constants need to be defined which will be used throughout the FINN build. These are:\n",
    "\n",
    "* **target_fps:** Target inference performance in frames per second. Note that target may not be achievable due to specific layer constraints, or due to resource limitations of the FPGA. If parallelization attributes are specified as part of folding_config_file that will override the target_fps setting here.\n",
    "* **mvau_wwidth_max:** controls the maximum width of the per-PE MVAU stream while exploring the parallelization attributes to reach target_fps Only relevant if target_fps is specified. Set this to a large value (e.g. 10000) if targeting full unfolding or very high performance.\n",
    "* **synth_clk_period_ns:** Target clock frequency (in nanoseconds) for Vivado synthesis. e.g. synth_clk_period_ns=5.0 will target a 200 MHz clock. If hls_clk_period_ns is not specified it will default to this value.\n",
    "* **output_dir:** this is the directory where the final build outputs will be written into.\n",
    "* **save_intermediate_models:** whether intermediate ONNX files will be saved during the build process. These can be useful for debugging if the build fails.\n",
    "* **shell_flow_type:** Target shell flow, only needed for generating full bitfiles where the FINN design is integrated into a shell. See documentation of ShellFlowType for options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "\n",
    "my_model_file = \"unsw_nb15_quantized_mlp_1bit.onnx\"\n",
    "my_model_name = \"mlp_unsw_nb15\"\n",
    "platform_name = \"Pynq-Z1\"\n",
    "output_dir    = \"output_%s_%s\" % (my_model_name, platform_name)\n",
    "\n",
    "target_fps = 100000\n",
    "mvau_wwidth_max = 10000\n",
    "synth_clk_period_ns = 10.0\n",
    "save_intermediate_models = True\n",
    "shell_flow_type = build_cfg.ShellFlowType.VIVADO_ZYNQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our model before we start building it to fit on hardware. For this, we will use the showInNetron method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'unsw_nb15_quantized_mlp_1bit.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbc9111b780>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "showInNetron(my_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the Model <a id=\"build_model\"></a>\n",
    "\n",
    "The following shows how to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from unsw_nb15_quantized_mlp_1bit.onnx\n",
      "Outputs will be generated at output_mlp_unsw_nb15_Pynq-Z1\n",
      "Build log is at output_mlp_unsw_nb15_Pynq-Z1/build_dataflow.log\n",
      "Running step: step_tidy_up [1/14]\n",
      "Running step: step_streamline [2/14]\n",
      "Running step: step_convert_to_hls [3/14]\n",
      "Running step: step_create_dataflow_partition [4/14]\n",
      "Running step: step_target_fps_parallelization [5/14]\n",
      "Running step: step_apply_folding_config [6/14]\n",
      "Running step: step_generate_estimate_reports [7/14]\n",
      "Running step: step_hls_ipgen [8/14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/workspace/finn/src/finn/transformation/fpgadataflow/hlssynth_ip.py\", line 68, in applyNodeLocal\n",
      "    inst.ipgen_singlenode_code()\n",
      "  File \"/workspace/finn/src/finn/custom_op/fpgadataflow/hlscustomop.py\", line 315, in ipgen_singlenode_code\n",
      "    assert os.path.isdir(ipgen_path), \"IPGen failed: %s not found\" % (ipgen_path)\n",
      "AssertionError: IPGen failed: /tmp/finn_dev_osboxes/code_gen_ipgen_StreamingFCLayer_Batch_3_wk93a2yb/project_StreamingFCLayer_Batch_3 not found\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/finn/src/finn/builder/build_dataflow.py\", line 126, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/workspace/finn/src/finn/builder/build_dataflow_steps.py\", line 244, in step_hls_ipgen\n",
      "    model = model.transform(HLSSynthIP())\n",
      "  File \"/workspace/finn-base/src/finn/core/modelwrapper.py\", line 132, in transform\n",
      "    transformed_model\n",
      "  File \"/workspace/finn-base/src/finn/transformation/base.py\", line 105, in apply\n",
      "    new_nodes_and_bool = p.map(self.applyNodeLocal, old_nodes, chunksize=1)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 266, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 644, in get\n",
      "    raise self._value\n",
      "AssertionError: IPGen failed: /tmp/finn_dev_osboxes/code_gen_ipgen_StreamingFCLayer_Batch_3_wk93a2yb/project_StreamingFCLayer_Batch_3 not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /opt/conda/lib/python3.6/multiprocessing/pool.py(644)get()\n",
      "-> raise self._value\n",
      "(Pdb) \n",
      "(Pdb) \n",
      "(Pdb) \n",
      "(Pdb) \n",
      "(Pdb) exit\n",
      "Build failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "\n",
    "cfg = build.DataflowBuildConfig(\n",
    "    # can specify detailed folding/FIFO/etc config with:\n",
    "    # folding_config_file=\"folding_config.json\",  \n",
    "    \n",
    "    output_dir          = output_dir,\n",
    "    target_fps          = target_fps,\n",
    "    mvau_wwidth_max     = mvau_wwidth_max,\n",
    "    synth_clk_period_ns = synth_clk_period_ns,\n",
    "    board               = platform_name,\n",
    "    shell_flow_type     = shell_flow_type,\n",
    "    \n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        #build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ],\n",
    "    save_intermediate_models=save_intermediate_models,\n",
    ")\n",
    "\n",
    "build.build_dataflow_cfg(my_model_file, cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Build Generated Files <a id=\"explore_generated\"></a>\n",
    "\n",
    "All generated output of the build can be found on the folder defined earlier as \"output_dir\" variable.\n",
    "\n",
    "Let's see what is inside this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_dataflow.log  intermediate_models  report\r\n"
     ]
    }
   ],
   "source": [
    "!ls $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the build directory there is the following:\n",
    "* The **\"build_dataflow.log\"** logs the output of the build flow.\n",
    "\n",
    "* The **\"report\" folder** contains all created reports regarding the build. \n",
    "\n",
    "* The **\"intermediate_models\" folder** holds all created models through the intermediate steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Reports <a id=\"reports\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the \"report\" folder there are the following reports:\n",
    "* estimate_layer_config_alternatives.json;\n",
    "* estimate_layer_cycles.json;\n",
    "* estimate_layer_resources.json;\n",
    "* estimate_network_performance.json;\n",
    "* op_and_param_counts.json;\n",
    "\n",
    "Some of them will be opened up shortly and briefly explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"critical_path_cycles\": 1184,\r\n",
      "  \"max_cycles\": 512,\r\n",
      "  \"max_cycles_node_name\": \"StreamingFCLayer_Batch_1\",\r\n",
      "  \"estimated_throughput_fps\": 195312.5,\r\n",
      "  \"estimated_latency_ns\": 11840.0\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "\"\"\"import json\n",
    "with open(output_dir +'/report/op_and_param_counts.json') as f:\n",
    "    dict_ = json.load(f)\n",
    "dict_ \"\"\"\n",
    "\n",
    "!cat  $output_dir/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this report shows us several parameters. Among these there is the estimated throughout in fps, and latency in nano seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"StreamingFCLayer_Batch_0\": {\r\n",
      "    \"op_mac_1bx1b\": 75904,\r\n",
      "    \"param_weight_1b\": 75904,\r\n",
      "    \"param_threshold_10b\": 128\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_1\": {\r\n",
      "    \"op_mac_1bx1b\": 8192,\r\n",
      "    \"param_weight_1b\": 8192,\r\n",
      "    \"param_threshold_8b\": 64\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_2\": {\r\n",
      "    \"op_mac_1bx1b\": 2048,\r\n",
      "    \"param_weight_1b\": 2048,\r\n",
      "    \"param_threshold_7b\": 32\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_3\": {\r\n",
      "    \"op_mac_1bx1b\": 32,\r\n",
      "    \"param_weight_1b\": 32,\r\n",
      "    \"param_threshold_6b\": 1\r\n",
      "  },\r\n",
      "  \"total\": {\r\n",
      "    \"op_mac_1bx1b\": 86176.0,\r\n",
      "    \"param_weight_1b\": 86176.0,\r\n",
      "    \"param_threshold_10b\": 128.0,\r\n",
      "    \"param_threshold_8b\": 64.0,\r\n",
      "    \"param_threshold_7b\": 32.0,\r\n",
      "    \"param_threshold_6b\": 1.0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/op_and_param_counts.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this file shows the amount of multiply-accumulate operations for each layer and the total amount. Note that the layer with the higher amount of nodes owns the highest amount of multiply-accumulate operations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"StreamingFCLayer_Batch_0\": {\r\n",
      "    \"BRAM_18K\": 17,\r\n",
      "    \"BRAM_efficiency\": 0.24223856209150327,\r\n",
      "    \"LUT\": 4264,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_1\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.4444444444444444,\r\n",
      "    \"LUT\": 433,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_2\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.1111111111111111,\r\n",
      "    \"LUT\": 350,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_3\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.001736111111111111,\r\n",
      "    \"LUT\": 327,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"total\": {\r\n",
      "    \"BRAM_18K\": 20.0,\r\n",
      "    \"LUT\": 5374.0,\r\n",
      "    \"URAM\": 0.0,\r\n",
      "    \"DSP\": 0.0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/estimate_layer_resources.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Intermediate Models <a id=\"intermediate_models\"></a>\n",
    "----------------------------------\n",
    "\n",
    "Inside this folder we can see that there are all intermediate models that were built with FINN build flow.\n",
    "* 1_step_tidy_up.onnx\t\t       \n",
    "* 2_step_streamline.onnx\t\t       \n",
    "* 3_step_convert_to_hls.onnx\t       \n",
    "* 4_step_create_dataflow_partition.onnx \n",
    "* 5_step_target_fps_parallelization.onnx\n",
    "* 6_step_apply_folding_config.onnx\n",
    "* 7_step_generate_estimate_reports.onnx\n",
    "* dataflow_parent.onnx\n",
    "\n",
    "We can look at these models with showInNetron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'output_mlp_unsw_nb15_Pynq-Z1/intermediate_models/1_step_tidy_up.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbc9106d080>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "layer = \"1_step_tidy_up\"\n",
    "showInNetron(output_dir +\"/intermediate_models/\" + layer + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'output_mlp_unsw_nb15_Pynq-Z1/intermediate_models/4_step_create_dataflow_partition.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbc919c1400>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = \"4_step_create_dataflow_partition\"\n",
    "showInNetron(output_dir +\"/intermediate_models/\" + layer + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'output_mlp_unsw_nb15_Pynq-Z1/intermediate_models/7_step_generate_estimate_reports.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbc919c14a8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = \"7_step_generate_estimate_reports\"\n",
    "showInNetron(output_dir +\"/intermediate_models/\" + layer + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with parameters \n",
    "\n",
    "Now let's decrease the \"target_fps\" and the \"mvau_wwidth_max\" and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fps = 1000\n",
    "mvau_wwidth_max = 1\n",
    "synth_clk_period_ns = 10.0\n",
    "save_intermediate_models = True\n",
    "shell_flow_type = build_cfg.ShellFlowType.VIVADO_ZYNQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from unsw_nb15_quantized_mlp_1bit.onnx\n",
      "Outputs will be generated at output_mlp_unsw_nb15_Pynq-Z1\n",
      "Build log is at output_mlp_unsw_nb15_Pynq-Z1/build_dataflow.log\n",
      "Running step: step_tidy_up [1/14]\n",
      "Running step: step_streamline [2/14]\n",
      "Running step: step_convert_to_hls [3/14]\n",
      "Running step: step_create_dataflow_partition [4/14]\n",
      "Running step: step_target_fps_parallelization [5/14]\n",
      "Running step: step_apply_folding_config [6/14]\n",
      "Running step: step_generate_estimate_reports [7/14]\n",
      "Running step: step_hls_ipgen [8/14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/workspace/finn/src/finn/transformation/fpgadataflow/hlssynth_ip.py\", line 68, in applyNodeLocal\n",
      "    inst.ipgen_singlenode_code()\n",
      "  File \"/workspace/finn/src/finn/custom_op/fpgadataflow/hlscustomop.py\", line 315, in ipgen_singlenode_code\n",
      "    assert os.path.isdir(ipgen_path), \"IPGen failed: %s not found\" % (ipgen_path)\n",
      "AssertionError: IPGen failed: /tmp/finn_dev_osboxes/code_gen_ipgen_StreamingFCLayer_Batch_3_041hkff4/project_StreamingFCLayer_Batch_3 not found\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/finn/src/finn/builder/build_dataflow.py\", line 126, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/workspace/finn/src/finn/builder/build_dataflow_steps.py\", line 244, in step_hls_ipgen\n",
      "    model = model.transform(HLSSynthIP())\n",
      "  File \"/workspace/finn-base/src/finn/core/modelwrapper.py\", line 132, in transform\n",
      "    transformed_model\n",
      "  File \"/workspace/finn-base/src/finn/transformation/base.py\", line 105, in apply\n",
      "    new_nodes_and_bool = p.map(self.applyNodeLocal, old_nodes, chunksize=1)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 266, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 644, in get\n",
      "    raise self._value\n",
      "AssertionError: IPGen failed: /tmp/finn_dev_osboxes/code_gen_ipgen_StreamingFCLayer_Batch_3_041hkff4/project_StreamingFCLayer_Batch_3 not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /opt/conda/lib/python3.6/multiprocessing/pool.py(644)get()\n",
      "-> raise self._value\n",
      "(Pdb) exit\n",
      "Build failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "\n",
    "cfg = build.DataflowBuildConfig(\n",
    "    # can specify detailed folding/FIFO/etc config with:\n",
    "    # folding_config_file=\"folding_config.json\",  \n",
    "    \n",
    "    output_dir          = output_dir,\n",
    "    target_fps          = target_fps,\n",
    "    mvau_wwidth_max     = mvau_wwidth_max,\n",
    "    synth_clk_period_ns = synth_clk_period_ns,\n",
    "    board               = platform_name,\n",
    "    shell_flow_type     = shell_flow_type,\n",
    "    \n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        #build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ],\n",
    "    save_intermediate_models=save_intermediate_models,\n",
    ")\n",
    "\n",
    "build.build_dataflow_cfg(my_model_file, cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"critical_path_cycles\": 86176,\r\n",
      "  \"max_cycles\": 75904,\r\n",
      "  \"max_cycles_node_name\": \"StreamingFCLayer_Batch_0\",\r\n",
      "  \"estimated_throughput_fps\": 1317.4536256323777,\r\n",
      "  \"estimated_latency_ns\": 861760.0\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"StreamingFCLayer_Batch_0\": {\r\n",
      "    \"op_mac_1bx1b\": 75904,\r\n",
      "    \"param_weight_1b\": 75904,\r\n",
      "    \"param_threshold_10b\": 128\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_1\": {\r\n",
      "    \"op_mac_1bx1b\": 8192,\r\n",
      "    \"param_weight_1b\": 8192,\r\n",
      "    \"param_threshold_8b\": 64\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_2\": {\r\n",
      "    \"op_mac_1bx1b\": 2048,\r\n",
      "    \"param_weight_1b\": 2048,\r\n",
      "    \"param_threshold_7b\": 32\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_3\": {\r\n",
      "    \"op_mac_1bx1b\": 32,\r\n",
      "    \"param_weight_1b\": 32,\r\n",
      "    \"param_threshold_6b\": 1\r\n",
      "  },\r\n",
      "  \"total\": {\r\n",
      "    \"op_mac_1bx1b\": 86176.0,\r\n",
      "    \"param_weight_1b\": 86176.0,\r\n",
      "    \"param_threshold_10b\": 128.0,\r\n",
      "    \"param_threshold_8b\": 64.0,\r\n",
      "    \"param_threshold_7b\": 32.0,\r\n",
      "    \"param_threshold_6b\": 1.0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/op_and_param_counts.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of multiply-accumulate operations remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"StreamingFCLayer_Batch_0\": {\r\n",
      "    \"BRAM_18K\": 5,\r\n",
      "    \"BRAM_efficiency\": 0.8236111111111111,\r\n",
      "    \"LUT\": 357,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_1\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.4444444444444444,\r\n",
      "    \"LUT\": 334,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_2\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.1111111111111111,\r\n",
      "    \"LUT\": 330,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_3\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.001736111111111111,\r\n",
      "    \"LUT\": 327,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"total\": {\r\n",
      "    \"BRAM_18K\": 8.0,\r\n",
      "    \"LUT\": 1348.0,\r\n",
      "    \"URAM\": 0.0,\r\n",
      "    \"DSP\": 0.0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/estimate_layer_resources.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'output_mlp_unsw_nb15_Pynq-Z1/intermediate_models/4_step_create_dataflow_partition.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbc910f5be0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = \"4_step_create_dataflow_partition\"\n",
    "showInNetron(output_dir +\"/intermediate_models/\" + layer + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
