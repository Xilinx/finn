{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End FINN Flow  for MobileNet-V1\n",
    "-------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import brevitas.onnx as bo\n",
    "import torch\n",
    "\n",
    "# get single image as input\n",
    "img = Image.open(\"/workspace/finn/tests/brevitas/king_charles.jpg\")\n",
    "img = img.resize((224, 224))\n",
    "img = np.asarray(img).copy().astype(np.int32)\n",
    "img = img.transpose(2, 0, 1)\n",
    "# our network is trained with BGR instead of RGB images,\n",
    "# so we need to invert the order of channels in the channel axis:\n",
    "img = img[::-1, :, :].copy()\n",
    "# finally, we need to subtract the mean per-channel pixel intensity\n",
    "# since this is how this network has been trained\n",
    "img[0] = img[0] - 104\n",
    "img[1] = img[1] - 117\n",
    "img[2] = img[2] - 123\n",
    "img = img.reshape(1, 3, 224, 224)\n",
    "input_tensor = torch.from_numpy(img).float()\n",
    "assert input_tensor.shape == (1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.test import get_test_model_trained\n",
    "mobilenet = get_test_model_trained(\"mobilenet\", 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# golden output\n",
    "# do forward pass in PyTorch/Brevitas\n",
    "mobilenet.eval()\n",
    "expected = mobilenet.forward(input_tensor).detach().numpy()\n",
    "expected_topk = expected.flatten()\n",
    "expected_top5 = np.argsort(expected_topk)[-5:]\n",
    "expected_top5 = np.flip(expected_top5)\n",
    "expected_top5_prob = []\n",
    "for index in expected_top5:\n",
    "    expected_top5_prob.append(expected_topk[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "\n",
    "bo.export_finn_onnx(mobilenet, (1, 3, 224, 224), \"quant_mobilenet_v1_4b.onnx\", input_t=input_tensor)\n",
    "model = ModelWrapper(\"quant_mobilenet_v1_4b.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'quant_mobilenet_v1_4b.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f74406cbef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "showInNetron(\"quant_mobilenet_v1_4b.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/infer_data_layouts.py:102: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'quant_mobilenet_v1_4b_before.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8e20aa1c50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.util.visualization import showInNetron\n",
    "model = ModelWrapper(\"quant_mobilenet_v1_4b.onnx\")\n",
    "\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.general import (\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    GiveUniqueParameterTensors,\n",
    ")\n",
    "from finn.transformation.insert_topk import InsertTopK\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "\n",
    "# tidy-up transformations\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(InsertTopK())\n",
    "# get initializer from Mul that will be absorbed into topk\n",
    "a0 = model.get_initializer(model.graph.node[-2].input[1])\n",
    "model = model.transform(absorb.AbsorbScalarMulIntoTopK())\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveUniqueParameterTensors())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "\n",
    "model.save(\"quant_mobilenet_v1_4b_before.onnx\")\n",
    "showInNetron(\"quant_mobilenet_v1_4b_before.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'quant_mobilenet_v1_4b_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8e20a57630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.double_to_single_float import DoubleToSingleFloat\n",
    "from finn.transformation.streamline.reorder import (\n",
    "    MoveMulPastDWConv,\n",
    "    MoveTransposePastScalarMul,\n",
    "    MoveFlattenPastAffine,\n",
    "    MoveFlattenPastTopK,\n",
    "    MoveScalarMulPastMatMul,\n",
    ")\n",
    "from finn.transformation.change_datalayout import ChangeDataLayoutQuantAvgPool2d\n",
    "from finn.transformation.streamline.collapse_repeated import CollapseRepeatedMul\n",
    "from finn.transformation.streamline.remove import RemoveIdentityOps\n",
    "\n",
    "model = ModelWrapper(\"quant_mobilenet_v1_4b_before.onnx\")\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(DoubleToSingleFloat())\n",
    "model = model.transform(MoveMulPastDWConv())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(ChangeDataLayoutQuantAvgPool2d())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(MoveTransposePastScalarMul())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model = model.transform(MoveFlattenPastAffine())\n",
    "model = model.transform(MoveFlattenPastTopK())\n",
    "model = model.transform(MoveScalarMulPastMatMul())\n",
    "model = model.transform(CollapseRepeatedMul())\n",
    "model = model.transform(RemoveIdentityOps())\n",
    "\n",
    "model.save(\"quant_mobilenet_v1_4b_streamlined.onnx\")\n",
    "showInNetron(\"quant_mobilenet_v1_4b_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'quant_mobilenet_v1_4b.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8e442a3128>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.streamline.absorb import AbsorbTransposeIntoMultiThreshold\n",
    "\n",
    "model = ModelWrapper(\"quant_mobilenet_v1_4b_streamlined.onnx\")\n",
    "\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "\n",
    "model.save(\"quant_mobilenet_v1_4b.onnx\")\n",
    "showInNetron(\"quant_mobilenet_v1_4b.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.core.onnx_exec as oxe\n",
    "model = ModelWrapper(\"quant_mobilenet_v1_4b.onnx\")\n",
    "idict = {model.graph.input[0].name: img.astype(np.float32)}\n",
    "odict = oxe.execute_onnx(model, idict, True)\n",
    "produced = odict[model.graph.output[0].name]\n",
    "produced_prob = odict[\"TopK_0_out0\"] * a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219 220 213 365 156]\n",
      "[[219 220 213 365 156]]\n",
      "[14.313654, 12.159303, 11.355986, 10.625698, 9.238149]\n",
      "[[[[14.313654 12.159303 11.355986 10.625697  9.23815 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(expected_top5)\n",
    "print(produced)\n",
    "print(expected_top5_prob)\n",
    "print(produced_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'quant_mobilenet_v1_4b.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f75b544c400>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(\"quant_mobilenet_v1_4b.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
