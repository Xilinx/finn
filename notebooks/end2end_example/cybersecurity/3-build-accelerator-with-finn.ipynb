{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Streaming Dataflow MLP Accelerator with FINN\n",
    "\n",
    "**Important: This notebook depends on the 2-cybersecurity-finn-verification notebook because we are using models that were created by these notebooks. So please make sure the needed .onnx files are generated prior to running this notebook.**\n",
    "\n",
    "<img align=\"left\" src=\"finn-example.png\" alt=\"drawing\" style=\"margin-right: 20px\" width=\"250\"/>\n",
    "\n",
    "In this notebook. we'll use the FINN compiler generate an FPGA accelerator with a streaming dataflow architecture from our quantized MLP for the cybersecurity task. The key idea in such architectures is to parallelize across layers as well as within layers by dedicating a proportionate amount of compute resources to each layer, illustrated on the figure to the left. You can read more about the general concept in the [FINN](https://arxiv.org/pdf/1612.07119) and [FINN-R](https://dl.acm.org/doi/pdf/10.1145/3242897) papers. This is done by mapping each layer to a Vivado HLS description, parallelizing each layer's implementation to the appropriate degree and using on-chip FIFOs to link up the layers to create the full accelerator.\n",
    "\n",
    "These implementations offer a good balance of performance and flexibility, but building them by hand is difficult and time-consuming. This is where the FINN compiler comes in: it can build streaming dataflow accelerators from an ONNX description to match the desired throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------\n",
    "1. [Define Some Necessary Parameters](#define_params)\n",
    "2. [Build the Model](#build_model)\n",
    "3. [Explore the Build Generated Files](#explore_generated)\n",
    "\n",
    "    3.1. [Reports](#reports)  \n",
    "    3.2  [Intermediate Models ](#intermediate_models) \n",
    "    \n",
    "    \n",
    "4. [Play With Parameters](#play_params)\n",
    "    \n",
    "    4.1 [Reports](#4reports)   \n",
    "    4.2 [Intermediate Models ](#4intermediate_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our model before we start building it. For this, we will use the showInNetron method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'unsw_nb15_quantized_mlp_1bit.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3b7a372e10>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_file = \"unsw_nb15_quantized_mlp_1bit.onnx\"\n",
    "\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "showInNetron(my_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Some Necessary Parameters <a id=\"define_params\"></a>\n",
    "\n",
    "All documentation on the FINN build can be found [here](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html).\n",
    "First we need to define some variables: such as the model name, model file and the platform name.\n",
    "Moreover, some constants need to be defined which will be used throughout the FINN build. These are:\n",
    "\n",
    "* **target_fps:** Target inference performance in frames per second. Note that target may not be achievable due to specific layer constraints, or due to resource limitations of the FPGA. If parallelization attributes are specified as part of folding_config_file that will override the target_fps setting here.\n",
    "* **mvau_wwidth_max:** controls the maximum width of the per-PE MVAU stream while exploring the parallelization attributes to reach target_fps Only relevant if target_fps is specified. Set this to a large value (e.g. 10000) if targeting full unfolding or very high performance.\n",
    "* **synth_clk_period_ns:** Target clock frequency (in nanoseconds) for Vivado synthesis. e.g. synth_clk_period_ns=5.0 will target a 200 MHz clock. If hls_clk_period_ns is not specified it will default to this value.\n",
    "* **output_dir:** this is the directory where the final build outputs will be written into.\n",
    "* **save_intermediate_models:** whether intermediate ONNX files will be saved during the build process. These can be useful for debugging if the build fails.\n",
    "* **shell_flow_type:** Target shell flow, only needed for generating full bitfiles where the FINN design is integrated into a shell. See [documentation](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html) of ShellFlowType for options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "\n",
    "my_model_file = \"unsw_nb15_quantized_mlp_1bit.onnx\"\n",
    "my_model_name = \"mlp_unsw_nb15\"\n",
    "platform_name = \"Pynq-Z1\"\n",
    "output_dir    = \"output_%s_%s\" % (my_model_name, platform_name)\n",
    "\n",
    "target_fps = 100000\n",
    "mvau_wwidth_max = 10000\n",
    "synth_clk_period_ns = 10.0\n",
    "save_intermediate_models = True\n",
    "shell_flow_type = build_cfg.ShellFlowType.VIVADO_ZYNQ\n",
    "enable_build_pdb_debug = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the Model <a id=\"build_model\"></a>\n",
    "\n",
    "The following shows how to build our model. We create a Build configuration which will be passed to the build_dataflow function. In this build configuration we can set up all desired attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from unsw_nb15_quantized_mlp_1bit.onnx\n",
      "Outputs will be generated at output_mlp_unsw_nb15_Pynq-Z1\n",
      "Build log is at output_mlp_unsw_nb15_Pynq-Z1/build_dataflow.log\n",
      "Running step: step_tidy_up [1/14]\n",
      "Running step: step_streamline [2/14]\n",
      "Running step: step_convert_to_hls [3/14]\n",
      "Running step: step_create_dataflow_partition [4/14]\n",
      "Running step: step_target_fps_parallelization [5/14]\n",
      "Running step: step_apply_folding_config [6/14]\n",
      "Running step: step_generate_estimate_reports [7/14]\n",
      "Running step: step_hls_ipgen [8/14]\n",
      "enable_build_pdb_debug not set in build config, exiting...\n",
      "Build failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/workspace/finn/src/finn/transformation/fpgadataflow/hlssynth_ip.py\", line 68, in applyNodeLocal\n",
      "    inst.ipgen_singlenode_code()\n",
      "  File \"/workspace/finn/src/finn/custom_op/fpgadataflow/hlscustomop.py\", line 321, in ipgen_singlenode_code\n",
      "    assert os.path.isdir(ipgen_path), \"IPGen failed: %s not found\" % (ipgen_path)\n",
      "AssertionError: IPGen failed: /tmp/finn_dev_osboxes/code_gen_ipgen_StreamingFCLayer_Batch_3_93qp61sr/project_StreamingFCLayer_Batch_3 not found\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/finn/src/finn/builder/build_dataflow.py\", line 126, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/workspace/finn/src/finn/builder/build_dataflow_steps.py\", line 300, in step_hls_ipgen\n",
      "    model = model.transform(HLSSynthIP())\n",
      "  File \"/workspace/finn-base/src/finn/core/modelwrapper.py\", line 140, in transform\n",
      "    transformed_model\n",
      "  File \"/workspace/finn-base/src/finn/transformation/base.py\", line 105, in apply\n",
      "    new_nodes_and_bool = p.map(self.applyNodeLocal, old_nodes, chunksize=1)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 266, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 644, in get\n",
      "    raise self._value\n",
      "AssertionError: IPGen failed: /tmp/finn_dev_osboxes/code_gen_ipgen_StreamingFCLayer_Batch_3_93qp61sr/project_StreamingFCLayer_Batch_3 not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "\n",
    "cfg = build.DataflowBuildConfig(\n",
    "    # can specify detailed folding/FIFO/etc config with:\n",
    "    # folding_config_file=\"folding_config.json\",  \n",
    "    \n",
    "    output_dir          = output_dir,\n",
    "    target_fps          = target_fps,\n",
    "    mvau_wwidth_max     = mvau_wwidth_max,\n",
    "    synth_clk_period_ns = synth_clk_period_ns,\n",
    "    board               = platform_name,\n",
    "    shell_flow_type     = shell_flow_type,\n",
    "    enable_build_pdb_debug=enable_build_pdb_debug,\n",
    "    \n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        #build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ],\n",
    "    save_intermediate_models=save_intermediate_models,\n",
    ")\n",
    "\n",
    "build.build_dataflow_cfg(my_model_file, cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Build Generated Files <a id=\"explore_generated\"></a>\n",
    "\n",
    "All generated output of the build can be found on the folder defined earlier as \"output_dir\" variable.\n",
    "\n",
    "Let's see what is inside this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_dataflow.log  intermediate_models  report\r\n"
     ]
    }
   ],
   "source": [
    "!ls $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the build directory we have:\n",
    "* The **\"build_dataflow.log\"** logs the output of the build flow.\n",
    "\n",
    "* The **\"report\" folder** contains all created reports regarding the build. \n",
    "\n",
    "* The **\"intermediate_models\" folder** holds all created models through the intermediate steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Reports <a id=\"reports\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the \"report\" folder there are the following reports:\n",
    "* estimate_layer_config_alternatives.json;\n",
    "* estimate_layer_cycles.json;\n",
    "* estimate_layer_resources.json;\n",
    "* estimate_network_performance.json;\n",
    "* op_and_param_counts.json;\n",
    "\n",
    "Some of them will be opened up shortly and briefly explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Performance Estimate\n",
    "As we can see, this report shows us several things, more specifically the estimated throughout in fps, latency in nano seconds and the layer with more bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"critical_path_cycles\": 1184,\r\n",
      "  \"max_cycles\": 512,\r\n",
      "  \"max_cycles_node_name\": \"StreamingFCLayer_Batch_1\",\r\n",
      "  \"estimated_throughput_fps\": 195312.5,\r\n",
      "  \"estimated_latency_ns\": 11840.0\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "\"\"\"import json\n",
    "with open(output_dir +'/report/op_and_param_counts.json') as f:\n",
    "    dict_ = json.load(f)\n",
    "dict_ \"\"\"\n",
    "\n",
    "!cat  $output_dir/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations and Parameter Count\n",
    "This file shows the amount of multiply-accumulate operations for each layer and the total amount. Note that the layer with the higher amount of nodes owns the highest amount of multiply-accumulate operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"StreamingFCLayer_Batch_0\": {\r\n",
      "    \"op_mac_1bx1b\": 75904,\r\n",
      "    \"param_weight_1b\": 75904,\r\n",
      "    \"param_threshold_10b\": 128\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_1\": {\r\n",
      "    \"op_mac_1bx1b\": 8192,\r\n",
      "    \"param_weight_1b\": 8192,\r\n",
      "    \"param_threshold_8b\": 64\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_2\": {\r\n",
      "    \"op_mac_1bx1b\": 2048,\r\n",
      "    \"param_weight_1b\": 2048,\r\n",
      "    \"param_threshold_7b\": 32\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_3\": {\r\n",
      "    \"op_mac_1bx1b\": 32,\r\n",
      "    \"param_weight_1b\": 32,\r\n",
      "    \"param_threshold_6b\": 1\r\n",
      "  },\r\n",
      "  \"total\": {\r\n",
      "    \"op_mac_1bx1b\": 86176.0,\r\n",
      "    \"param_weight_1b\": 86176.0,\r\n",
      "    \"param_threshold_10b\": 128.0,\r\n",
      "    \"param_threshold_8b\": 64.0,\r\n",
      "    \"param_threshold_7b\": 32.0,\r\n",
      "    \"param_threshold_6b\": 1.0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/op_and_param_counts.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources per Layer Estimate\n",
    "This file shows the amount of hardware resources utilized per each layer and the the total amount of BRAMs, LUTs, URAMs and DSPs needed to implement this model on hardware. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"StreamingFCLayer_Batch_0\": {\r\n",
      "    \"BRAM_18K\": 17,\r\n",
      "    \"BRAM_efficiency\": 0.24223856209150327,\r\n",
      "    \"LUT\": 4264,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"URAM_efficiency\": 1,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_1\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.4444444444444444,\r\n",
      "    \"LUT\": 433,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"URAM_efficiency\": 1,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_2\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.1111111111111111,\r\n",
      "    \"LUT\": 350,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"URAM_efficiency\": 1,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_3\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.001736111111111111,\r\n",
      "    \"LUT\": 327,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"URAM_efficiency\": 1,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"total\": {\r\n",
      "    \"BRAM_18K\": 20.0,\r\n",
      "    \"LUT\": 5374.0,\r\n",
      "    \"URAM\": 0.0,\r\n",
      "    \"DSP\": 0.0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/estimate_layer_resources.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Intermediate Models <a id=\"intermediate_models\"></a>\n",
    "\n",
    "Inside the **intermediate_models** folder we can find all intermediate models generated from FINN build flow.\n",
    "* 1_step_tidy_up.onnx\t\t       \n",
    "* 2_step_streamline.onnx\t\t       \n",
    "* 3_step_convert_to_hls.onnx\t       \n",
    "* 4_step_create_dataflow_partition.onnx \n",
    "* 5_step_target_fps_parallelization.onnx\n",
    "* 6_step_apply_folding_config.onnx\n",
    "* 7_step_generate_estimate_reports.onnx\n",
    "* dataflow_parent.onnx\n",
    "\n",
    "We can look at these models with showInNetron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'output_mlp_unsw_nb15_Pynq-Z1/intermediate_models/2_step_streamline.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3b7a3afdd8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = \"2_step_streamline\"\n",
    "showInNetron(output_dir +\"/intermediate_models/\" + layer + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'output_mlp_unsw_nb15_Pynq-Z1/intermediate_models/3_step_convert_to_hls.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3b7a3a6cf8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = \"3_step_convert_to_hls\"\n",
    "showInNetron(output_dir +\"/intermediate_models/\" + layer + \".onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "\n",
    "# 4. Play With Parameters <a id=\"play_params\"></a>\n",
    "\n",
    "Now let's decrease the \"target_fps\" and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir    = \"output2_%s_%s\" % (my_model_name, platform_name)\n",
    "\n",
    "target_fps = 10000\n",
    "mvau_wwidth_max = 10000\n",
    "synth_clk_period_ns = 10.0\n",
    "save_intermediate_models = True\n",
    "shell_flow_type = build_cfg.ShellFlowType.VIVADO_ZYNQ\n",
    "#large_fifo_mem_style = \"distributed\"\n",
    "#default_mem_mode = \"const\" makes no diff\n",
    "enable_build_pdb_debug = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from unsw_nb15_quantized_mlp_1bit.onnx\n",
      "Outputs will be generated at output2_mlp_unsw_nb15_Pynq-Z1\n",
      "Build log is at output2_mlp_unsw_nb15_Pynq-Z1/build_dataflow.log\n",
      "Running step: step_tidy_up [1/14]\n",
      "Running step: step_streamline [2/14]\n",
      "Running step: step_convert_to_hls [3/14]\n",
      "enable_build_pdb_debug not set in build config, exiting...\n",
      "Build failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspace/finn/src/finn/builder/build_dataflow.py\", line 126, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/workspace/finn/src/finn/builder/build_dataflow_steps.py\", line 185, in step_convert_to_hls\n",
      "    mem_mode = cfg.default_mem_mode.value\n",
      "AttributeError: 'str' object has no attribute 'value'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "\n",
    "cfg = build.DataflowBuildConfig(\n",
    "    # can specify detailed folding/FIFO/etc config with:\n",
    "    # folding_config_file=\"folding_config.json\",  \n",
    "    \n",
    "    output_dir          = output_dir,\n",
    "    target_fps          = target_fps,\n",
    "    mvau_wwidth_max     = mvau_wwidth_max,\n",
    "    synth_clk_period_ns = synth_clk_period_ns,\n",
    "    board               = platform_name,\n",
    "    shell_flow_type     = shell_flow_type,\n",
    "    enable_build_pdb_debug= enable_build_pdb_debug,\n",
    "    default_mem_mode    = default_mem_mode,\n",
    "    \n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "        build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "        #build_cfg.DataflowOutputType.BITFILE,\n",
    "        build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "    ],\n",
    "    save_intermediate_models=save_intermediate_models,\n",
    ")\n",
    "\n",
    "build.build_dataflow_cfg(my_model_file, cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Reports  <a id=\"4reports\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Performance Estimate\n",
    "As we can see, the amount of critical path cycles has increased. The throughout is lower to match the target throughput and the latency has increased. The layer with more bottlenecks remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"critical_path_cycles\": 1184,\r\n",
      "  \"max_cycles\": 512,\r\n",
      "  \"max_cycles_node_name\": \"StreamingFCLayer_Batch_1\",\r\n",
      "  \"estimated_throughput_fps\": 195312.5,\r\n",
      "  \"estimated_latency_ns\": 11840.0\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations and Parameters Count \n",
    "The amount of multiply-accumulate operations remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"StreamingFCLayer_Batch_0\": {\r\n",
      "    \"op_mac_1bx1b\": 75904,\r\n",
      "    \"param_weight_1b\": 75904,\r\n",
      "    \"param_threshold_10b\": 128\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_1\": {\r\n",
      "    \"op_mac_1bx1b\": 8192,\r\n",
      "    \"param_weight_1b\": 8192,\r\n",
      "    \"param_threshold_8b\": 64\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_2\": {\r\n",
      "    \"op_mac_1bx1b\": 2048,\r\n",
      "    \"param_weight_1b\": 2048,\r\n",
      "    \"param_threshold_7b\": 32\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_3\": {\r\n",
      "    \"op_mac_1bx1b\": 32,\r\n",
      "    \"param_weight_1b\": 32,\r\n",
      "    \"param_threshold_6b\": 1\r\n",
      "  },\r\n",
      "  \"total\": {\r\n",
      "    \"op_mac_1bx1b\": 86176.0,\r\n",
      "    \"param_weight_1b\": 86176.0,\r\n",
      "    \"param_threshold_10b\": 128.0,\r\n",
      "    \"param_threshold_8b\": 64.0,\r\n",
      "    \"param_threshold_7b\": 32.0,\r\n",
      "    \"param_threshold_6b\": 1.0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/op_and_param_counts.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Resources Estimate\n",
    "The amount of resources has decreased. The model is using less BRAM and less LUTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"StreamingFCLayer_Batch_0\": {\r\n",
      "    \"BRAM_18K\": 17,\r\n",
      "    \"BRAM_efficiency\": 0.24223856209150327,\r\n",
      "    \"LUT\": 4264,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"URAM_efficiency\": 1,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_1\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.4444444444444444,\r\n",
      "    \"LUT\": 433,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"URAM_efficiency\": 1,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_2\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.1111111111111111,\r\n",
      "    \"LUT\": 350,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"URAM_efficiency\": 1,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"StreamingFCLayer_Batch_3\": {\r\n",
      "    \"BRAM_18K\": 1,\r\n",
      "    \"BRAM_efficiency\": 0.001736111111111111,\r\n",
      "    \"LUT\": 327,\r\n",
      "    \"URAM\": 0,\r\n",
      "    \"URAM_efficiency\": 1,\r\n",
      "    \"DSP\": 0\r\n",
      "  },\r\n",
      "  \"total\": {\r\n",
      "    \"BRAM_18K\": 20.0,\r\n",
      "    \"LUT\": 5374.0,\r\n",
      "    \"URAM\": 0.0,\r\n",
      "    \"DSP\": 0.0\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat  $output_dir/report/estimate_layer_resources.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Intermediate Models <a id=\"4intermediate_models\"></a>\n",
    "Now, let's have a look at the intermediate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'output2_mlp_unsw_nb15_Pynq-Z1/intermediate_models/2_step_streamline.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3aedf75cc0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = \"2_step_streamline\"\n",
    "showInNetron(output_dir +\"/intermediate_models/\" + layer + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'output2_mlp_unsw_nb15_Pynq-Z1/intermediate_models/3_step_convert_to_hls.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3b7a393cf8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = \"3_step_convert_to_hls\" \n",
    "showInNetron(output_dir +\"/intermediate_models/\" + layer + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
