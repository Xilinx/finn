{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINN - Transformation passes\n",
    "--------------------------------------\n",
    "In this notebook the idea behind transformation passes in FINN will be explained and with the help of an example the procedure of a transformation will be shown.\n",
    "\n",
    "We'll use the following utility functions to print the source code for function calls (`showSrc()`) and to visualize a network using netron (`showInNetron()`) in the Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information\n",
    "-----------------------------\n",
    "* changes (transforms) the given graph\n",
    "* input: ModelWrapper\n",
    "* returns the changed model (ModelWrapper) and flag `model_was_changed`\n",
    "\n",
    "Transformation passes have a base class and must inherit from that. Transformations are meant to be applied using .transform function from the ModelWrapper. This function makes a deep copy of the input model by default. The next cell shows .transform of ModelWrapper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .transform() from ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def transform(self, transformation, make_deepcopy=True):\n",
      "        \"\"\"Applies given Transformation repeatedly until no more changes can be made\n",
      "        and returns a transformed ModelWrapper instance.\n",
      "\n",
      "        If make_deepcopy is specified, operates on a new (deep)copy of model.\n",
      "        \"\"\"\n",
      "        transformed_model = self\n",
      "        if make_deepcopy:\n",
      "            transformed_model = copy.deepcopy(self)\n",
      "        model_was_changed = True\n",
      "        while model_was_changed:\n",
      "            (transformed_model, model_was_changed) = transformation.apply(\n",
      "                transformed_model\n",
      "            )\n",
      "        return transformed_model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.core.modelwrapper import ModelWrapper\n",
    "showSrc(ModelWrapper.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the function is called, the model, the name of the transformation and, if required, the flag make_deepcopy are passed. It is also possible not to make a copy of the model. In this case `make_deepcopy` must be set to False. Then the branch `if make_deepcopy:` would not be taken and no copy of the model would be made. \n",
    "\n",
    "The unchanged model is first passed to the variable `transformed_model` to pass this variable on to the transformation later. \n",
    "\n",
    "`model_was_changed` indicates whether the transformation needs to be applied more then once. Because it needs to be applied at least one time `model_was_changed` is first set to True and then depending on the return values of the transformation function the transformation can be applied more then once. \n",
    "\n",
    "**Important**: Due to the structure of this function, `model_was_changed` must be set to False at some point. Otherwise the loop is infinite.\n",
    "    \n",
    "\n",
    "Each new transformation must correspond to the scheme of the base class and contain at least the function `apply(model)`, which returns the changed model and a bool value for `model_was_changed`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Base Class     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Transformation(ABC):\n",
      "    \"\"\"Transformation class all transformations are based on. Contains only\n",
      "    abstract method apply() every transformation has to fill.\"\"\"\n",
      "\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "\n",
      "    @abstractmethod\n",
      "    def apply(self, model):\n",
      "        pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.base import Transformation\n",
    "\n",
    "showSrc(Transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base class is abstract class (`import ABC`) with only one abstract method (`apply()`) which gets the model as input. To show what a transformation should look like, the following example is taken from FINN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - ConvertSubToAdd\n",
    "-----------------------------\n",
    "The transformation replaces all subtraction nodes in a model with addition nodes with appropriate sign. For that an onnx model is loaded which contains one subtraction node. \n",
    "    \n",
    "Netron is used to visualize the result before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load('../LFCW1A1.onnx')\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "onnx_model = ModelWrapper(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '../LFCW1A1.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc625ac0a20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron('../LFCW1A1.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.base import Transformation\n",
    "\n",
    "class ConvertSubToAdd(Transformation):\n",
    "    def apply(self, model):\n",
    "        graph = model.graph\n",
    "        for n in graph.node:\n",
    "            if n.op_type == \"Sub\":\n",
    "                A = model.get_initializer(n.input[1])\n",
    "                if A is not None:\n",
    "                    n.op_type = \"Add\"\n",
    "                    model.set_initializer(n.input[1], -A)\n",
    "        return (model, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the transformation class must be imported. Then a class can be created for the new transformation, which is derived from the base class. In this case the transformation has only the `apply()` function. \n",
    "\n",
    "All nodes are checked by first extracting the graph from the model and then iterating over the node list. With the help of .op_type the operation type of the node can be checked, if the node is a subtraction node the condition `if n.op_type == \"Sub\"` is true. It may be that the subtraction input of the node has no value, this is checked with `model.get_initializer(n.input[1])`. \n",
    "    \n",
    "    \n",
    "**Important:** FINN always assumes a certain order of inputs, this is especially important if you want to create additional custom operation nodes.\n",
    "\n",
    "When the input is initialized, the operation type of the node is converted to `\"Add\"`, this can simply be done by using the equal sign. Then the sign of the initial value must be changed. For this the ModelWrapper function `.set_initializer` can be used.\n",
    "\n",
    "At the end the changed model is returned and `model_was_changed` is set to False, because the transformation has to be executed only once.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_transformed = onnx_model.transform(ConvertSubToAdd())\n",
    "onnx_model_transformed.save('/tmp/LFCW1A1_changed.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/LFCW1A1_changed.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://0.0.0.0:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc625ac09b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron('/tmp/LFCW1A1_changed.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Transformation\n",
    "---------------------------------\n",
    "Some of the transformations in FINN can be performed in parallel on individual nodes. The following `NodeLocalTransformation` is required for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NodeLocalTransformation(Transformation):\n",
      "    \"\"\"\n",
      "    Parent class for transformations, which can be executed locally to one node\n",
      "    by accessing and modifying the attributes of only that node.\n",
      "    This class can then automatically parallelize the transformation.\n",
      "    Transformations sublcassing NodeLocalTransformation must implement the\n",
      "    abstract method applyNodeLocal().\n",
      "\n",
      "    To control the degree of parallelization, specify the num_workers argument\n",
      "    in the constructor, using one of the following values:\n",
      "    * None: use NUM_DEFAULT_WORKERS environment variable\n",
      "    * 0: use all available CPU cores\n",
      "    * (any other int>0): set number of parallel workers\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, num_workers=None):\n",
      "        super().__init__()\n",
      "        if num_workers is None:\n",
      "            self._num_workers = get_num_default_workers()\n",
      "        else:\n",
      "            self._num_workers = num_workers\n",
      "        assert self._num_workers >= 0, \"Number of workers must be nonnegative.\"\n",
      "        if self._num_workers == 0:\n",
      "            self._num_workers = mp.cpu_count()\n",
      "\n",
      "    @abstractmethod\n",
      "    def applyNodeLocal(self, node):\n",
      "        pass\n",
      "\n",
      "    def apply(self, model):\n",
      "        # Remove old nodes from the current model\n",
      "        old_nodes = []\n",
      "        for i in range(len(model.graph.node)):\n",
      "            old_nodes.append(model.graph.node.pop())\n",
      "\n",
      "        # Execute transformation in parallel\n",
      "        with mp.Pool(self._num_workers) as p:\n",
      "            new_nodes_and_bool = p.map(self.applyNodeLocal, old_nodes, chunksize=1)\n",
      "\n",
      "        # extract nodes and check if the transformation needs to run again\n",
      "        # Note: .pop() had initially reversed the node order\n",
      "        run_again = False\n",
      "        for node, run in reversed(new_nodes_and_bool):\n",
      "            # Reattach new nodes to old model\n",
      "            model.graph.node.append(node)\n",
      "            if run is True:\n",
      "                run_again = True\n",
      "\n",
      "        return (model, run_again)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.base import NodeLocalTransformation\n",
    "\n",
    "showSrc(NodeLocalTransformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations that are to be executed in parallel must have the method `applyNodeLocal()` implemented. Please note that the transformation is only executed on a single node, the parallel transformations do not have access to the entire model or tensors. Parallelization has the advantage that especially time-consuming transformations such as compilation can be executed more effectively. \n",
    "\n",
    "To control the degree of parallelization the argument `num_workers` can be specified. When the Docker container is started, the env variable `NUM_DEFAULT_WORKERS` is set to 1 by default, this can be increased depending on the system. You can also set the number of workers manually to a specific value when calling a transformation that allows parallelization. If the value is set to 0, all available CPU cores are used.\n",
    "\n",
    "In the following we want to take a closer look at the implementation using the compile transformation as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class CompileCppSim(NodeLocalTransformation):\n",
      "    \"\"\"For every node: compile C++ code in node attribute \"code_gen_dir_cppsim\"\n",
      "    and save path to executables in node attribute \"executable_path\".\n",
      "    All nodes in the graph must have the fpgadataflow backend attribute.\n",
      "\n",
      "    To use these executables, exec_mode must be set to \"cppsim\" (using transformation\n",
      "    SetExecMode) and the model has to be executed using execute_onnx() from\n",
      "    finn.core.onnx_exec\n",
      "\n",
      "    * num_workers (int or None) number of parallel workers, see documentation in\n",
      "      NodeLocalTransformation for more details.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, num_workers=None):\n",
      "        super().__init__(num_workers=num_workers)\n",
      "\n",
      "    def applyNodeLocal(self, node):\n",
      "        op_type = node.op_type\n",
      "        if is_fpgadataflow_node(node) is True:\n",
      "            try:\n",
      "                # lookup op_type in registry of CustomOps\n",
      "                inst = registry.getCustomOp(node)\n",
      "                # ensure that code is generated\n",
      "                assert (\n",
      "                    inst.get_nodeattr(\"code_gen_dir_cppsim\") != \"\"\n",
      "                ), \"\"\"Node\n",
      "                attribute \"code_gen_dir_cppsim\" is not set. Please run\n",
      "                Transformation PrepareCppSim first.\"\"\"\n",
      "                # call the compilation function for this node\n",
      "                inst.compile_singlenode_code()\n",
      "                # ensure that executable path is now set\n",
      "                assert (\n",
      "                    inst.get_nodeattr(\"executable_path\") != \"\"\n",
      "                ), \"\"\"Transformation\n",
      "                compile was not successful, there is no path to executables set\n",
      "                in node attribute \"executable_path\".\"\"\"\n",
      "            except KeyError:\n",
      "                # exception if op_type is not supported\n",
      "                raise Exception(\n",
      "                    \"Custom op_type %s is currently not supported.\" % op_type\n",
      "                )\n",
      "        return (node, False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "\n",
    "showSrc(CompileCppSim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class is derived from the NodeLocalTransformation class and performs the compilation at every node that is fpgadataflow node."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
