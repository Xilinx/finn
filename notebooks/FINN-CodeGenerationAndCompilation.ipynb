{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINN - Code Generation and Compilation\n",
    "-----------------------------------------------------------------\n",
    "<font size=\"3\">This notebook is about code generation and compilation to enable execution of FINN custom operation nodes. \n",
    "\n",
    "Following showSrc function is used to print the source code of function calls in the Jupyter notebook:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def showSrc(what):\n",
    "    print(\"\".join(inspect.getsourcelines(what)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "-------------\n",
    "* <font size=\"3\">Example model</font>\n",
    "* <font size=\"3\">Code generation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example model\n",
    "<font size=\"3\">To show the code generation and compilation of a node, an example model with a streaming fclayer node is first created. To learn more about FINN custom operation nodes, please take a look at notebook [FINN-CustomOps](FINN-CustomOps.ipynb).\n",
    "\n",
    "First TensorProto and helper are imported from ONNX. These functions can be used to create tensors, nodes, graphs and models in ONNX. Additional functions from `util` and the classes `DataType` and `ModelWrapper` are needed. More information about `DataType` and `ModelWrapper` can be found in Jupyter notebook [FINN-ModelWrapper](FINN-ModelWrapper.ipynb).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import TensorProto, helper\n",
    "import finn.core.utils as util\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Then all parameters, that are needed to create a streaming fclayer, are set. To keep the example clear small values are chosen. For more information about the parameters please take look at the documentation of the [finn-hls library](https://finn-hlslib.readthedocs.io/en/latest/).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idt = wdt = odt = DataType.BIPOLAR\n",
    "mw = 8\n",
    "mh = 8\n",
    "pe = 4\n",
    "simd = 4\n",
    "nf = mh // pe\n",
    "sf = mw // simd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">A `tensor_value_info` is created for all tensors involved. In this case there is one tensor for the weights besides the input and output tensors. Then an input list is created containing the two inputs (`\"inp\"`and `\"weights\"`).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = helper.make_tensor_value_info(\"inp\", TensorProto.FLOAT, [1, sf, simd])\n",
    "weights = helper.make_tensor_value_info(\"weights\", TensorProto.FLOAT, [mw, mh])\n",
    "outp = helper.make_tensor_value_info(\"outp\", TensorProto.FLOAT, [1, nf, pe])\n",
    "node_inp_list = [\"inp\", \"weights\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Now the node can be created. The operation type is set to `\"StreamingFCLayer_Batch\"` and the rest of the attributes are set appropriately. The relevant attributes for the activation of the code generation and compilation are:</font>\n",
    "* <font size=\"3\">**`domain=\"finn\"`**: specifies that the created node is a FINN-Custom Op</font>\n",
    "* <font size=\"3\">**`backend=\"fpgadataflow\"`**: specifies that it is a node that corresponds to a function in the finn-hls library</font>\n",
    "* <font size=\"3\">**`code_gen_dir\"`**: specifies the path to the directory where the generated c++ files are (is set during code generation)</font>\n",
    "* <font size=\"3\">**`executable_path\"`**: specifies the path to the executable created after compilation (is set during compilation)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCLayer_node = helper.make_node(\n",
    "        \"StreamingFCLayer_Batch\",\n",
    "        node_inp_list,\n",
    "        [\"outp\"],\n",
    "        domain=\"finn\",\n",
    "        backend=\"fpgadataflow\",\n",
    "        code_gen_dir=\"\",\n",
    "        executable_path=\"\",\n",
    "        resType=\"ap_resource_lut()\",\n",
    "        MW=mw,\n",
    "        MH=mh,\n",
    "        SIMD=simd,\n",
    "        PE=pe,\n",
    "        noActivation=1,\n",
    "        binaryXnorMode=1,\n",
    "        inputDataType=idt.name,\n",
    "        weightDataType=wdt.name,\n",
    "        outputDataType=odt.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> The node is packed into a graph environment and the inputs and outputs are set.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = helper.make_graph(\n",
    "        nodes=[FCLayer_node], name=\"fclayer_graph\", inputs=[inp], outputs=[outp]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">A model is now created from the graph, which is then converted into a ModelWrapper object for further processing in FINN. Afterwards the ModelWrapper internal functions can be used to set the FINN data types and the initializer for the weights. Since this is an example, the weights are not taken from the training, but random values are generated using the utility function `gen_finn_dt_tensor()`. This function gets a FINN datatype and a shape and generates a tensor with values of this datatype in the desired shape.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = helper.make_model(graph, producer_name=\"fclayer-model\")\n",
    "model = ModelWrapper(model)\n",
    "\n",
    "model.set_tensor_datatype(\"inp\", idt)\n",
    "model.set_tensor_datatype(\"outp\", odt)\n",
    "model.set_tensor_datatype(\"weights\", wdt)\n",
    "W = util.gen_finn_dt_tensor(wdt, (mw, mh))\n",
    "model.set_initializer(\"weights\", W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">The model is saved and then netron is used to visualize the resulting model. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"FCLayer_graph.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'FCLayer_graph.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "import netron\n",
    "netron.start('FCLayer_graph.onnx', port=8081, host=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://0.0.0.0:8081/\" style=\"position: relative; width: 100%;\" height=\"400\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"http://0.0.0.0:8081/\" style=\"position: relative; width: 100%;\" height=\"400\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generation\n",
    "<font size=\"3\">Code generation is a transformation that can be applied to the model. For more information about transformation passes, see Jupyter Notebook [FINN-HowToTransformPass](FINN-HowToTransformPass.ipynb).\n",
    "\n",
    "The code generation transformation is shown below.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class CodeGen(Transformation):\n",
      "    \"\"\"Code generation for all nodes in model\"\"\"\n",
      "\n",
      "    def apply(self, model):\n",
      "        for node in model.graph.node:\n",
      "            if node.domain == \"finn\":\n",
      "                backend_attribute = get_by_name(node.attribute, \"backend\")\n",
      "                if backend_attribute is None:\n",
      "                    continue\n",
      "                backend_value = backend_attribute.s.decode(\"UTF-8\")\n",
      "                if backend_value == \"fpgadataflow\":\n",
      "                    _codegen_single_node(node, model)\n",
      "        return (model, False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.codegen import CodeGen\n",
    "showSrc(CodeGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">The transformation pass iterates over all nodes in the model and if `domain=\"finn\"` and `backend=\"fpgadataflow\"` is True, the function `_codegen_single_node()` is executed which is also part of the transformation pass and is shown below. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _codegen_single_node(node, model):\n",
      "    \"\"\"Call custom implementation to generate code for single custom node\n",
      "    and create folder that contains all the generated files\"\"\"\n",
      "    op_type = node.op_type\n",
      "    try:\n",
      "        # lookup op_type in registry of CustomOps\n",
      "        inst = registry.custom_op[op_type](node)\n",
      "        # get the path of the code generation directory\n",
      "        code_gen_dir = inst.get_nodeattr(\"code_gen_dir\")\n",
      "        # ensure that there is a directory\n",
      "        if code_gen_dir == \"\" or not os.path.isdir(code_gen_dir):\n",
      "            code_gen_dir = tmp.mkdtemp(prefix=\"code_gen_\" + str(node.op_type) + \"_\")\n",
      "            inst.set_nodeattr(\"code_gen_dir\", code_gen_dir)\n",
      "        # ensure that there is generated code inside the dir\n",
      "        inst.code_generation(model)\n",
      "    except KeyError:\n",
      "        # exception if op_type is not supported\n",
      "        raise Exception(\"Custom op_type %s is currently not supported.\" % op_type)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.codegen import _codegen_single_node\n",
    "showSrc(_codegen_single_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">An instance of the node is created and checked for the attribute `code_gen_dir`. If the attribute is not set, a temporary directory is created and the attribute is set accordingly. \n",
    "\n",
    "Then the `code_generation()` function of the instance is called. If an error occurs during this process, this is probably due to the fact that the selected CustomOp is not yet supported. The following description of the code generation within the CustomOp instance may lead to overlaps with the Jupyter notebook [FINN-CustomOps](FINN-CustomOps.ipynb).\n",
    "\n",
    "In order to clarify the individual components involved in code generation, an instance of the node is first created, as in the `_codegen_single_node` function. This is done by looking up the op_type in the [registry](https://github.com/Xilinx/finn/blob/dev/src/finn/custom_op/registry.py) of CustomOps. The instance contains a template for code generation which is shown below.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        #include \"cnpy.h\"\n",
      "        #include \"npy2apintstream.hpp\"\n",
      "        #include <vector>\n",
      "        #include \"bnn-library.h\"\n",
      "\n",
      "        // includes for network parameters\n",
      "        $GLOBALS$\n",
      "\n",
      "        // defines for network parameters\n",
      "        $DEFINES$\n",
      "\n",
      "        int main(){\n",
      "\n",
      "        $STREAMDECLARATIONS$\n",
      "\n",
      "        $READNPYDATA$\n",
      "\n",
      "        $DOCOMPUTE$\n",
      "\n",
      "        $DATAOUTSTREAM$\n",
      "\n",
      "        $SAVEASCNPY$\n",
      "\n",
      "        }\n",
      "\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import finn.custom_op.registry as registry\n",
    "node = FCLayer_node\n",
    "op_type = FCLayer_node.op_type\n",
    "inst = registry.custom_op[op_type](node)\n",
    "print(inst.docompute_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">The template has some general constructs, like the inclusion of bnn-library.h, which contains the references to the finn-hls library, and of cnpy.h and npy2apintstream.hpp, which support the transfer of python numpy arrays in c++. The idea of this template is to replace the variables marked with `$ $` with c++ calls during code generation. Then the template can be written into a .cpp file and be compiled. \n",
    "\n",
    "The sub-functions that are called during code generation are shown below.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def code_generation(self, model):\n",
      "        node = self.onnx_node\n",
      "        self.generate_params(model)\n",
      "        self.global_includes()\n",
      "        self.defines()\n",
      "        self.read_npy_data()\n",
      "        self.strm_decl()\n",
      "        self.docompute()\n",
      "        self.dataoutstrm()\n",
      "        self.save_as_npy()\n",
      "\n",
      "        template = self.docompute_template\n",
      "\n",
      "        for key in self.code_gen_dict:\n",
      "            # transform list into long string separated by '\\n'\n",
      "            code_gen_line = \"\\n\".join(self.code_gen_dict[key])\n",
      "            template = template.replace(key, code_gen_line)\n",
      "        code_gen_dir = self.get_nodeattr(\"code_gen_dir\")\n",
      "        f = open(os.path.join(code_gen_dir, \"execute_{}.cpp\".format(node.op_type)), \"w\")\n",
      "        f.write(template)\n",
      "        f.close()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from finn.custom_op.fpgadataflow.streamingfclayer_batch import StreamingFCLayer_Batch\n",
    "showSrc(StreamingFCLayer_Batch.code_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
