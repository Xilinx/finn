{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5420d782",
   "metadata": {},
   "source": [
    "Small Test Net - Alon Tchelet MSc Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a1db6",
   "metadata": {},
   "source": [
    "# Brevitas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726a95b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36887421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general use libraries\n",
    "import numpy as np\n",
    "\n",
    "# Brevitaas ad PyTorch libraries\n",
    "import torch\n",
    "from torch.nn import Module, ModuleList, Sequential, Conv2d, Linear, ReLU, MaxPool2d, Flatten\n",
    "from brevitas.nn import QuantIdentity, QuantConv2d, QuantLinear, QuantReLU, QuantMaxPool2d\n",
    "from brevitas.inject.defaults import *\n",
    "from brevitas.inject import *\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.restrict_val import FloatToIntImplType\n",
    "from brevitas.quant.solver import WeightQuantSolver, ActQuantSolver\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.zero_point import ZeroZeroPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da1024",
   "metadata": {},
   "source": [
    "## Set up network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec3b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQuant(ExtendedInjector):\n",
    "    bit_width_impl_type = BitWidthImplType.CONST\n",
    "    scaling_impl_type = ScalingImplType.CONST\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND\n",
    "    restrict_scaling_type = RestrictValueType.FP\n",
    "    zero_point_impl = ZeroZeroPoint\n",
    "    narrow_range = True\n",
    "    quant_delay_steps = 50\n",
    "    \n",
    "    @value\n",
    "    def quant_type(bit_width):\n",
    "        if bit_width == 1:\n",
    "            return QuantType.BINARY\n",
    "        else:\n",
    "            return QuantType.INT   \n",
    "\n",
    "class MyActQuant(MyQuant, ActQuantSolver):\n",
    "    min_val = 0.0\n",
    "    max_val = 6.0\n",
    "    signed = False \n",
    "    \n",
    "class MyWeightQuant(MyQuant, WeightQuantSolver):\n",
    "    scaling_const = 0.1\n",
    "    signed = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e46664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLeNet(Module):\n",
    "\n",
    "    # init for CIFAR-10\n",
    "    def __init__(self, weight_bit_width=8, act_bit_width=8):\n",
    "        super(QLeNet, self).__init__()\n",
    "        self.weight_bit_width = int(np.clip(weight_bit_width, 1, 8))\n",
    "        self.act_bit_width = int(np.clip(act_bit_width, 1, 8))\n",
    "\n",
    "        self.conv1 = Sequential(\n",
    "            QuantIdentity(\n",
    "            act_quant=Int8ActPerTensorFloatMinMaxInit,\n",
    "            min_val = -1.0,\n",
    "            max_val = 1.0 - 2.0 ** (-7),\n",
    "            signed = True,\n",
    "            restrict_scaling_type=RestrictValueType.POWER_OF_TWO),\n",
    "            QuantConv2d(3, 6, 5, bias=False, \n",
    "                        weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(act_quant=MyActQuant, bit_width=self.act_bit_width),\n",
    "            QuantMaxPool2d(2, 2))\n",
    "        self.conv2 = Sequential(\n",
    "            QuantConv2d(6, 16, 5, bias=False, \n",
    "                        weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(act_quant=MyActQuant, bit_width=self.act_bit_width),\n",
    "            QuantMaxPool2d(2, 2))\n",
    "        self.flat = Flatten()\n",
    "        self.fc1 = Sequential(\n",
    "            QuantLinear(400, 120, bias=True,\n",
    "                        weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(act_quant=MyActQuant, bit_width=self.act_bit_width))\n",
    "        self.fc2 = Sequential(\n",
    "            QuantLinear(120, 84, bias=True,\n",
    "                        weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width),\n",
    "            QuantReLU(act_quant=MyActQuant, bit_width=self.act_bit_width))\n",
    "        self.fc3 = QuantLinear(84, 10, bias=False,\n",
    "                               weight_quant=MyWeightQuant, weight_bit_width=self.weight_bit_width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1b1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "        # init for CIFAR-10\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = Sequential(\n",
    "            Conv2d(3, 6, 5),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2))\n",
    "        self.conv2 = Sequential(\n",
    "            Conv2d(6, 16, 5),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2))\n",
    "        self.flat = Flatten()\n",
    "        self.fc1 = Sequential(\n",
    "            Linear(400, 120),\n",
    "            ReLU())\n",
    "        self.fc2 = Sequential(\n",
    "            Linear(120, 84),\n",
    "            ReLU())\n",
    "        self.fc3 = Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenets = []\n",
    "lenets_names = []\n",
    "\n",
    "# for i in range(2, 9):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i}\")\n",
    "    \n",
    "# for i in range(2, 8):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i+1, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i+1}a{i}\")\n",
    "\n",
    "# for i in range(1, 8):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i+1))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i+1}\")\n",
    "    \n",
    "# for i in range(2, 7):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i+2, act_bit_width=i))\n",
    "#     lenets_names.append(f\"lenet_w{i+2}a{i}\")\n",
    "\n",
    "# for i in range(1, 7):\n",
    "#     lenets.append(QLeNet(weight_bit_width=i, act_bit_width=i+2))\n",
    "#     lenets_names.append(f\"lenet_w{i}a{i+2}\")\n",
    "\n",
    "lenet_w3a4 = QLeNet(weight_bit_width=3, act_bit_width=4)\n",
    "lenets.append(lenet_w3a4)\n",
    "lenets_names.append(\"lenet_w3a4\")\n",
    "lenet_w4a3 = QLeNet(weight_bit_width=4, act_bit_width=3)\n",
    "lenets.append(lenet_w4a3)\n",
    "lenets_names.append(\"lenet_w4a3\")\n",
    "lenet_w2a4 = QLeNet(weight_bit_width=2, act_bit_width=4)\n",
    "lenets.append(lenet_w2a4)\n",
    "lenets_names.append(\"lenet_w2a4\")\n",
    "lenet_w2a3 = QLeNet(weight_bit_width=2, act_bit_width=3)\n",
    "lenets.append(lenet_w2a3)\n",
    "lenets_names.append(\"lenet_w2a3\")\n",
    "\n",
    "lenets.append(LeNet())\n",
    "lenets_names.append(\"lenet_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741da6b5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4d3a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import SubsetRandomSampler as Sampler\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "split = .9\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                        download=True, transform=transform)\n",
    "validset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "train_len = len(trainset)\n",
    "split = int(split*train_len)\n",
    "idx = list(range(train_len))\n",
    "train_idx, valid_idx = idx[split:], idx[:split]\n",
    "train_samples = Sampler(train_idx)\n",
    "valid_samples = Sampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                           sampler=train_samples, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                          sampler=valid_samples, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e6e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizers = []\n",
    "lr = 0.001\n",
    "epochs = 13\n",
    "\n",
    "for net in lenets:\n",
    "    optimizers.append(optim.Adam(net.parameters(), lr=lr, weight_decay=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f67922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training for net: lenet_w3a4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] training loss: 2.082113 - valid loss: 1.933648\n",
      "[Epoch: 2] training loss: 1.847574 - valid loss: 1.736572\n",
      "[Epoch: 3] training loss: 1.704948 - valid loss: 1.663259\n",
      "[Epoch: 4] training loss: 1.618376 - valid loss: 1.616328\n",
      "[Epoch: 5] training loss: 1.550714 - valid loss: 1.607521\n",
      "[Epoch: 6] training loss: 1.498649 - valid loss: 1.561098\n",
      "[Epoch: 7] training loss: 1.451308 - valid loss: 1.545549\n",
      "[Epoch: 8] training loss: 1.398344 - valid loss: 1.564969\n",
      "[Epoch: 9] training loss: 1.362514 - valid loss: 1.519654\n",
      "[Epoch: 10] training loss: 1.313594 - valid loss: 1.550168\n",
      "[Epoch: 11] training loss: 1.292945 - valid loss: 1.510521\n",
      "[Epoch: 12] training loss: 1.259286 - valid loss: 1.516885\n",
      "[Epoch: 13] training loss: 1.230766 - valid loss: 1.494909\n",
      "Finished training for net: lenet_w3a4\n",
      "\n",
      "Started training for net: lenet_w4a3\n",
      "[Epoch: 1] training loss: 2.077851 - valid loss: 1.864883\n",
      "[Epoch: 2] training loss: 1.809396 - valid loss: 1.804215\n",
      "[Epoch: 3] training loss: 1.692304 - valid loss: 1.698200\n",
      "[Epoch: 4] training loss: 1.628833 - valid loss: 1.660147\n",
      "[Epoch: 5] training loss: 1.545027 - valid loss: 1.624193\n",
      "[Epoch: 6] training loss: 1.495347 - valid loss: 1.615037\n",
      "[Epoch: 7] training loss: 1.450233 - valid loss: 1.601873\n",
      "[Epoch: 8] training loss: 1.414914 - valid loss: 1.574937\n",
      "[Epoch: 9] training loss: 1.363755 - valid loss: 1.592155\n",
      "[Epoch: 10] training loss: 1.326852 - valid loss: 1.553820\n",
      "[Epoch: 11] training loss: 1.279376 - valid loss: 1.616870\n",
      "[Epoch: 12] training loss: 1.245286 - valid loss: 1.591539\n",
      "[Epoch: 13] training loss: 1.212787 - valid loss: 1.548253\n",
      "Finished training for net: lenet_w4a3\n",
      "\n",
      "Started training for net: lenet_w2a4\n",
      "[Epoch: 1] training loss: 2.113488 - valid loss: 1.901177\n",
      "[Epoch: 2] training loss: 1.845614 - valid loss: 1.754909\n",
      "[Epoch: 3] training loss: 1.720601 - valid loss: 1.699383\n",
      "[Epoch: 4] training loss: 1.635465 - valid loss: 1.666281\n",
      "[Epoch: 5] training loss: 1.588257 - valid loss: 1.640309\n",
      "[Epoch: 6] training loss: 1.542908 - valid loss: 1.616962\n",
      "[Epoch: 7] training loss: 1.516056 - valid loss: 1.577146\n",
      "[Epoch: 8] training loss: 1.467031 - valid loss: 1.758381\n",
      "[Epoch: 9] training loss: 1.459220 - valid loss: 1.557654\n",
      "[Epoch: 10] training loss: 1.409110 - valid loss: 1.553623\n",
      "[Epoch: 11] training loss: 1.365362 - valid loss: 1.611043\n",
      "[Epoch: 12] training loss: 1.329478 - valid loss: 1.578505\n",
      "[Epoch: 13] training loss: 1.299602 - valid loss: 1.534157\n",
      "Finished training for net: lenet_w2a4\n",
      "\n",
      "Started training for net: lenet_w2a3\n",
      "[Epoch: 1] training loss: 2.125410 - valid loss: 1.993495\n",
      "[Epoch: 2] training loss: 1.919832 - valid loss: 1.818004\n",
      "[Epoch: 3] training loss: 1.758374 - valid loss: 1.709059\n",
      "[Epoch: 4] training loss: 1.671222 - valid loss: 1.680070\n",
      "[Epoch: 5] training loss: 1.594942 - valid loss: 1.714769\n",
      "[Epoch: 6] training loss: 1.532560 - valid loss: 1.589166\n",
      "[Epoch: 7] training loss: 1.469562 - valid loss: 1.601136\n",
      "[Epoch: 8] training loss: 1.419022 - valid loss: 1.574514\n",
      "[Epoch: 9] training loss: 1.394975 - valid loss: 1.639154\n",
      "[Epoch: 10] training loss: 1.370538 - valid loss: 1.539907\n",
      "[Epoch: 11] training loss: 1.322630 - valid loss: 1.610965\n",
      "[Epoch: 12] training loss: 1.298210 - valid loss: 1.563078\n",
      "[Epoch: 13] training loss: 1.270316 - valid loss: 1.604225\n",
      "Finished training for net: lenet_w2a3\n",
      "\n",
      "Started training for net: lenet_base\n",
      "[Epoch: 1] training loss: 2.069681 - valid loss: 1.877909\n",
      "[Epoch: 2] training loss: 1.760544 - valid loss: 1.695827\n",
      "[Epoch: 3] training loss: 1.663534 - valid loss: 1.688200\n",
      "[Epoch: 4] training loss: 1.564370 - valid loss: 1.588617\n",
      "[Epoch: 5] training loss: 1.495490 - valid loss: 1.555488\n",
      "[Epoch: 6] training loss: 1.434092 - valid loss: 1.531627\n",
      "[Epoch: 7] training loss: 1.365563 - valid loss: 1.501156\n",
      "[Epoch: 8] training loss: 1.304172 - valid loss: 1.485961\n",
      "[Epoch: 9] training loss: 1.231510 - valid loss: 1.500581\n",
      "[Epoch: 10] training loss: 1.190898 - valid loss: 1.517051\n",
      "[Epoch: 11] training loss: 1.136526 - valid loss: 1.476621\n",
      "[Epoch: 12] training loss: 1.069831 - valid loss: 1.475843\n",
      "[Epoch: 13] training loss: 1.003745 - valid loss: 1.522756\n",
      "Finished training for net: lenet_base\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for n, net in enumerate(lenets):\n",
    "    print(f\"Started training for net: {lenets_names[n]}\")\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        train_loss = valid_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizers[n].zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizers[n].step()\n",
    "\n",
    "            # print statistics\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= i\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                vloss = criterion(outputs, labels)\n",
    "                valid_loss += vloss.item()\n",
    "            valid_loss /= i\n",
    "        print(f\"[Epoch: {epoch+1}] training loss: {train_loss:.6f} - valid loss: {valid_loss:.6f}\")\n",
    "        train_loss = valid_loss = 0.0\n",
    "        \n",
    "#         correct = 0\n",
    "#         top3 = 0\n",
    "#         top5 = 0\n",
    "#         total = 0\n",
    "#         with torch.no_grad():\n",
    "#             for data in testloader:\n",
    "#                 images, labels = data\n",
    "#                 outputs = net(images)\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 top3_outputs = torch.argsort(outputs.data, 1)[:, -3:]\n",
    "#                 top5_outputs = torch.argsort(outputs.data, 1)[:, -5:]\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "#                 top3 += sum([(out==labels[i]).sum() for i, out in enumerate(top3_outputs)])\n",
    "#                 top5 += sum([(out==labels[i]).sum() for i, out in enumerate(top5_outputs)])\n",
    "#         print(f\"[Epoch: {epoch+1}] Network Accuracy:\\tTop-1: {100 * correct / total : .2f},\\tTop-3: {100 * top3 / total : .2f},\\tTop-5: {100 * top5 / total : .2f}\")\n",
    "            \n",
    "    print(f\"Finished training for net: {lenets_names[n]}\\n\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6b585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network\n",
    "for n, net in enumerate(lenets):\n",
    "    path = f\"./{lenets_names[n]}.pth\"\n",
    "    torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4bc72",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d37e65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001,\tBatch size: 32,\tIterations: 13\n",
      "lenet_w3a4 Network Accuracy:\tTop-1:  46.44,\tTop-3:  79.86,\tTop-5:  92.15\n",
      "lenet_w4a3 Network Accuracy:\tTop-1:  45.50,\tTop-3:  78.32,\tTop-5:  91.18\n",
      "lenet_w2a4 Network Accuracy:\tTop-1:  45.17,\tTop-3:  78.42,\tTop-5:  91.04\n",
      "lenet_w2a3 Network Accuracy:\tTop-1:  43.29,\tTop-3:  78.17,\tTop-5:  91.16\n",
      "lenet_base Network Accuracy:\tTop-1:  49.42,\tTop-3:  80.04,\tTop-5:  92.13\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# if you need to load the networks\n",
    "#\n",
    "# lenet_og = QLeNet()\n",
    "# lenet_w8 = QLeNet(weight_bit_width=8)\n",
    "# lenet_w4 = QLeNet(weight_bit_width=4)\n",
    "# lenet_w2 = QLeNet(weight_bit_width=2)\n",
    "# lenet_w8a8 = QLeNet(weight_bit_width=8, act_bit_width=8)\n",
    "# lenet_w4a4 = QLeNet(weight_bit_width=4, act_bit_width=4)\n",
    "# lenet_w2a2 = QLeNet(weight_bit_width=2, act_bit_width=2)\n",
    "# lenets = [lenet_w8a8, lenet_w4a4, lenet_w2a2, lenet_w8, lenet_w4, lenet_w2, lenet_og]\n",
    "# lenets_names = [\"lenet_w8a8\", \"lenet_w4a4\", \"lenet_w2a2\", \"lenet_w8\", \"lenet_w4\", \"lenet_w2\", \"lenet_og\"]\n",
    "# for n, net in enumerate(lenets):\n",
    "#     path = f'./{lenets_names[n]}.pth'\n",
    "#     net.load_state_dict(torch.load(path))\n",
    "#\n",
    "\n",
    "print(f\"Learning rate: {lr},\\tBatch size: {batch_size},\\tIterations: {epochs}\")\n",
    "for n, net in enumerate(lenets):    \n",
    "    correct = 0\n",
    "    top3 = 0\n",
    "    top5 = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            top3_outputs = torch.argsort(outputs.data, 1)[:, -3:]\n",
    "            top5_outputs = torch.argsort(outputs.data, 1)[:, -5:]\n",
    "#             print(f'Predicted: {predicted} - Labels: {labels}\\n')\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            top3 += sum([(out==labels[i]).sum() for i, out in enumerate(top3_outputs)])\n",
    "            top5 += sum([(out==labels[i]).sum() for i, out in enumerate(top5_outputs)])\n",
    "    print(f\"{lenets_names[n]} Network Accuracy:\\tTop-1: {100 * correct / total : .2f},\\tTop-3: {100 * top3 / total : .2f},\\tTop-5: {100 * top5 / total : .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0f617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenets = []\n",
    "lenets_names = []\n",
    "\n",
    "lenet_w3a4 = QLeNet(weight_bit_width=3, act_bit_width=4)\n",
    "lenets.append(lenet_w3a4)\n",
    "lenets_names.append(\"lenet_w3a4\")\n",
    "lenet_w4a3 = QLeNet(weight_bit_width=4, act_bit_width=3)\n",
    "lenets.append(lenet_w4a3)\n",
    "lenets_names.append(\"lenet_w4a3\")\n",
    "lenet_w2a4 = QLeNet(weight_bit_width=2, act_bit_width=4)\n",
    "lenets.append(lenet_w2a4)\n",
    "lenets_names.append(\"lenet_w2a4\")\n",
    "lenet_w2a3 = QLeNet(weight_bit_width=2, act_bit_width=3)\n",
    "lenets.append(lenet_w2a3)\n",
    "lenets_names.append(\"lenet_w2a3\")\n",
    "\n",
    "lenets.append(LeNet())\n",
    "lenets_names.append(\"lenet_base\")\n",
    "\n",
    "for n, net in enumerate(lenets):\n",
    "    path = f'./{lenets_names[n]}.pth'\n",
    "    net.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f90930",
   "metadata": {},
   "source": [
    "# FINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3506e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23d4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINN-Brevitas imports\n",
    "import brevitas.onnx as bo\n",
    "\n",
    "# ONNX libraries\n",
    "import onnx\n",
    "import onnx.numpy_helper as nph\n",
    "import onnxruntime as rt\n",
    "\n",
    "# Network display methods - Netron\n",
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "# FINN Network Preperation imports\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.infer_shapes import InferShapes\n",
    "from finn.transformation.fold_constants import FoldConstants\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.util.pytorch import ToTensor\n",
    "from finn.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.core.datatype import DataType\n",
    "from finn.transformation.insert_topk import InsertTopK\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from finn.transformation.infer_data_layouts import InferDataLayouts\n",
    "from finn.transformation.general import RemoveUnusedTensors\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "from finn.custom_op.registry import getCustomOp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268e877",
   "metadata": {},
   "source": [
    "## Brevitas Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1e2f78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting lenet_w3a4\n",
      "exporting lenet_w4a3\n",
      "exporting lenet_w2a4\n",
      "exporting lenet_w2a3\n",
      "exporting lenet_base\n"
     ]
    }
   ],
   "source": [
    "for n, net in enumerate(lenets):\n",
    "    print(f\"exporting {lenets_names[n]}\")\n",
    "    onnx_export_path = f\"./onnx/{lenets_names[n]}.onnx\"\n",
    "    bo.export_finn_onnx(net, (1, 3, 32, 32), onnx_export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f54c59",
   "metadata": {},
   "source": [
    "## Network Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfadd0a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select which network to work with\n",
    "net_n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40dd984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving './onnx/lenet_w3a4.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "toDisplay = True\n",
    "# display net through Netron\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990164f",
   "metadata": {},
   "source": [
    "### Tidy ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ec254f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}.onnx\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedc379",
   "metadata": {},
   "source": [
    "### Add Pre/Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d325dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn-base/src/finn/transformation/infer_data_layouts.py:114: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_tidy.onnx\")\n",
    "\n",
    "# pre-processing\n",
    "in_name = model.graph.input[0].name\n",
    "in_shape = model.get_tensor_shape(in_name)\n",
    "totensor = ToTensor()\n",
    "bo.export_finn_onnx(totensor, in_shape, f\"./onnx/{lenets_names[net_n]}_pre.onnx\")\n",
    "pre_model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_pre.onnx\")\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "in_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(in_name, DataType.UINT8)\n",
    "\n",
    "# post-processing\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c0be1",
   "metadata": {},
   "source": [
    "### Streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01258d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_streamline.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "# model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed0d00",
   "metadata": {},
   "source": [
    "### convert to HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b8c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/custom_op/fpgadataflow/thresholding_batch.py:341: UserWarning: Setting 0-valued first threshold to 1 to avoid vivado_hls bug\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_hls.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_streamline.onnx\")\n",
    "model = model.transform(to_hls.InferQuantizedStreamingFCLayer())\n",
    "model = model.transform(to_hls.InferThresholdingLayer())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(to_hls.InferConvInpGen())\n",
    "model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "model = model.transform(InferDataLayouts())\n",
    "\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6dc7f7",
   "metadata": {},
   "source": [
    "### Create Dataflow Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffe9812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_dataflow.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_hls.onnx\")\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(f\"./onnx/{lenets_names[net_n]}_dataflow_parent.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_dataflow.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b26034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "parent_model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_parent.onnx\")\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model.save(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fcde36",
   "metadata": {},
   "source": [
    "### Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02a59a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomOp wrapper is of class StreamingFCLayer_Batch #1\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 75\n",
      "MH: ('i', True, 0) = 6\n",
      "resType: ('s', False, 'lut', {'auto', 'dsp', 'lut'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = INT8\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1, 28, 28]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'ultra', 'auto', 'distributed', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #2\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 150\n",
      "MH: ('i', True, 0) = 16\n",
      "resType: ('s', False, 'lut', {'auto', 'dsp', 'lut'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT14\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1, 10, 10]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'ultra', 'auto', 'distributed', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #3\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 400\n",
      "MH: ('i', True, 0) = 120\n",
      "resType: ('s', False, 'lut', {'auto', 'dsp', 'lut'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'ultra', 'auto', 'distributed', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #4\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 120\n",
      "MH: ('i', True, 0) = 84\n",
      "resType: ('s', False, 'lut', {'auto', 'dsp', 'lut'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = UINT4\n",
      "accDataType: ('s', False, 'INT32') = INT14\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 0\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'ultra', 'auto', 'distributed', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n",
      "CustomOp wrapper is of class StreamingFCLayer_Batch #5\n",
      "PE: ('i', True, 0) = 1\n",
      "SIMD: ('i', True, 0) = 1\n",
      "MW: ('i', True, 0) = 84\n",
      "MH: ('i', True, 0) = 10\n",
      "resType: ('s', False, 'lut', {'auto', 'dsp', 'lut'}) = lut\n",
      "ActVal: ('i', False, 0) = 0\n",
      "inputDataType: ('s', True, '') = UINT4\n",
      "weightDataType: ('s', True, '') = INT3\n",
      "outputDataType: ('s', True, '') = INT16\n",
      "accDataType: ('s', False, 'INT32') = INT16\n",
      "binaryXnorMode: ('i', False, 0, {0, 1}) = 0\n",
      "noActivation: ('i', False, 0, {0, 1}) = 1\n",
      "numInputVectors: ('ints', False, [1]) = [1]\n",
      "mem_mode: ('s', False, 'const', {'external', 'const', 'decoupled'}) = const\n",
      "ram_style: ('s', False, 'auto', {'ultra', 'auto', 'distributed', 'block'}) = auto\n",
      "runtime_writeable_weights: ('i', False, 0, {0, 1}) = 0\n",
      "backend: ('s', True, 'fpgadataflow') = fpgadataflow\n",
      "code_gen_dir_cppsim: ('s', False, '') = \n",
      "code_gen_dir_ipgen: ('s', False, '') = \n",
      "executable_path: ('s', False, '') = \n",
      "ipgen_path: ('s', False, '') = \n",
      "ip_path: ('s', False, '') = \n",
      "ip_vlnv: ('s', False, '') = \n",
      "exec_mode: ('s', False, '', {'', 'cppsim', 'rtlsim'}) = \n",
      "cycles_rtlsim: ('i', False, 0) = 0\n",
      "cycles_estimate: ('i', False, 0) = 0\n",
      "rtlsim_trace: ('s', False, '') = \n",
      "res_estimate: ('s', False, '') = \n",
      "res_hls: ('s', False, '') = \n",
      "res_synth: ('s', False, '') = \n",
      "rtlsim_so: ('s', False, '') = \n",
      "slr: ('i', False, -1) = -1\n",
      "mem_port: ('s', False, '') = \n",
      "partition_id: ('i', False, 0) = 0\n",
      "device_id: ('i', False, 0) = 0\n",
      "inFIFODepth: ('i', False, 2) = 2\n",
      "outFIFODepth: ('i', False, 2) = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "# fc0w = getCustomOp(fc0)\n",
    "# print(\"CustomOp wrapper is of class \" + fc0w.__class__.__name__)\n",
    "for i, layer in enumerate(layers):\n",
    "    temp_op = getCustomOp(layer)\n",
    "    print(f\"CustomOp wrapper is of class StreamingFCLayer_Batch #{i+1}\")\n",
    "    for item in temp_op.get_nodeattr_types():\n",
    "        print(f\"{item}: {temp_op.get_nodeattr_types()[item]} = {temp_op.get_nodeattr(item)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "303225b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving './onnx/lenet_w3a4_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_dataflow_model.onnx\")\n",
    "\n",
    "# set convolution-input (sliding window) layers folding factors\n",
    "sw_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator\")\n",
    "sw_folding = [3, \n",
    "              2]\n",
    "for layer, simd in zip(sw_layers, sw_folding):\n",
    "    fcl_inst = getCustomOp(layer)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    \n",
    "# set fully-connected layers folding factors\n",
    "fc_layers = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")\n",
    "fc_folding = [\n",
    "    (1, 3, 16),\n",
    "    (2, 2, 16),\n",
    "    (1, 4, 16),\n",
    "    (1, 1, 16),\n",
    "    (1, 1, 16)\n",
    "]\n",
    "for layer, (pe, simd, ififo) in zip(fc_layers, fc_folding):\n",
    "    fcl_inst = getCustomOp(layer)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepth\", ififo)\n",
    "    \n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")\n",
    "\n",
    "if toDisplay:\n",
    "    showInNetron(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df781a4c",
   "metadata": {},
   "source": [
    "## Hardware Build and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d59e91",
   "metadata": {},
   "source": [
    "### Hardware Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finn/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 18 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n",
      "/workspace/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:154: UserWarning: Overriding input FIFO depth to 32\n",
      "  warnings.warn(\"Overriding input FIFO depth to 32\")\n",
      "/workspace/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:200: UserWarning: Overriding output FIFO depth to 32\n",
      "  warnings.warn(\"Overriding output FIFO depth to 32\")\n",
      "/workspace/finn/src/finn/custom_op/fpgadataflow/thresholding_batch.py:341: UserWarning: Setting 0-valued first threshold to 1 to avoid vivado_hls bug\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "\n",
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_folded.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = \"ZCU102\", period_ns = 10))\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_hw.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954b36f",
   "metadata": {},
   "source": [
    "### Hardware Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "\n",
    "ip = os.getenv(\"PYNQ_IP\", \"128.131.80.208\")\n",
    "username = os.getenv(\"PYNQ_USERNAME\", \"xilinx\")\n",
    "password = os.getenv(\"PYNQ_PASSWORD\", \"xilinx\")\n",
    "port = os.getenv(\"PYNQ_PORT\", 22)\n",
    "target_dir = os.getenv(\"PYNQ_TARGET_DIR\", \"/home/xilinx/zcu102\")\n",
    "options = \"-o PreferredAuthentications=publickey -o PasswordAuthentication=no\"\n",
    "\n",
    "model = ModelWrapper(f\"./onnx/{lenets_names[net_n]}_hw.onnx\")\n",
    "model = model.transform(DeployToPYNQ(ip, port, username, password, target_dir))\n",
    "model.save(f\"./onnx/{lenets_names[net_n]}_pynq.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f41d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed35af65ba39e5a16f3dcb5d74a0040cbc997642885eadf410410f5c61311ebb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
